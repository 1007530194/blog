<!DOCTYPE html>
<html lang="en">


<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>朴素贝叶斯</title>
  <meta name="description" content="第4章 基于概率论的分类方法：朴素贝叶斯">

  <link rel="canonical" href="https://1007530194.github.io/blog2/11ReadBook/04MachineLearningPractice/04%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.html">
  <link rel="alternate" type="application/rss+xml" title="MyBook" href="https://1007530194.github.io/blog2/feed.xml">

  <meta property="og:url"         content="https://1007530194.github.io/blog2/11ReadBook/04MachineLearningPractice/04%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="朴素贝叶斯" />
<meta property="og:description" content="第4章 基于概率论的分类方法：朴素贝叶斯" />
<meta property="og:image"       content="" />


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage":
    "https://1007530194.github.io/blog2/11ReadBook/04MachineLearningPractice/04%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.html",
  "headline":
    "朴素贝叶斯",
  "datePublished":
    "2019-06-13T15:02:54+08:00",
  "dateModified":
    "2019-06-13T15:02:54+08:00",
  "description":
    "第4章 基于概率论的分类方法：朴素贝叶斯",
  "author": {
    "@type": "Person",
    "name": "niult"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://1007530194.github.io/blog2",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://1007530194.github.io/blog2",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/blog2/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">
  <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/blog2/assets/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    CommonHTML: {
        linebreaks: {
            automatic: true,
        },
    },
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/blog2';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="/blog2/assets/js/anchor.min.js"  type="text/javascript"></script>
  <script>

initFunction(function () {
    anchors.add("main h1, main h2, main h3, main h4")
});

</script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="/blog2/assets/js/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->


<!-- Display Thebelab button in each code cell -->
<script>
    /**
     * Set up thebelab button for code blocks
     */

    const thebelabCellButton = id =
    >
    `<a id="thebelab-cell-button-${id}" class="btn thebebtn o-tooltip--left" data-tooltip="Interactive Mode">
    <img src="https://raw.githubusercontent.com/1007530194/images/master/picgo/blog/logo/edit-button.svg" alt="Start interactive mode">
  </a>`


    const addThebelabButtonToCodeCells = () =
    >
    {

        const codeCells = document.querySelectorAll('div.input_area > div.highlighter-rouge:not(.output) pre')
        codeCells.forEach((codeCell, index) = > {
            const id = codeCellId(index)
            codeCell.setAttribute('id', id)
        if (document.getElementById("thebelab-cell-button-" + id) == null) {
            codeCell.insertAdjacentHTML('afterend', thebelabCellButton(id));
        }
    })
    }

    initFunction(addThebelabButtonToCodeCells);
</script>



<script type="text/x-thebe-config">
    {
      requestKernel: true,
      binderOptions: {
        repo: 'jupyter/jupyter-book',
        ref: 'gh-pages',
      },
      codeMirrorConfig: {
        theme: "abcdef"
      },
      kernelOptions: {
        name: 'python3',
      }
    }
</script>
<script src="https://unpkg.com/thebelab@0.4.0/lib/index.js"></script>
<script>
    /**
     * Add attributes to Thebelab blocks
     */

    const initThebelab = () => {
        const addThebelabToCodeCells = () => {
            console.log("Adding thebelab to code cells...");
            // If Thebelab hasn't loaded, wait a bit and try again. This
            // happens because we load ClipboardJS asynchronously.
            if (window.thebelab === undefined) {
                setTimeout(addThebelabToCodeCells, 250)
            return
            }

            // If we already detect a Thebelab cell, don't re-run
            if (document.querySelectorAll('div.thebelab-cell').length > 0) {
                return;
            }

            // Find all code cells, replace with Thebelab interactive code cells
            const codeCells = document.querySelectorAll('.input_area pre')
            codeCells.forEach((codeCell, index) => {
                const id = codeCellId(index)
                codeCell.setAttribute('data-executable', 'true')

                // Figure out the language it uses and add this too
                var parentDiv = codeCell.parentElement.parentElement;
                var arrayLength = parentDiv.classList.length;
                for (var ii = 0; ii < arrayLength; ii++) {
                    var parts = parentDiv.classList[ii].split('language-');
                    if (parts.length === 2) {
                        // If found, assign dataLanguage and break the loop
                        var dataLanguage = parts[1];
                        break;
                    }
                }
                codeCell.setAttribute('data-language', dataLanguage)

                // If the code cell is hidden, show it
                var inputCheckbox = document.querySelector(`input#hidebtn${codeCell.id}`);
                if (inputCheckbox !== null) {
                    setCodeCellVisibility(inputCheckbox, 'visible');
                }
            });

            // Remove the event listener from the page so keyboard press doesn't
            // Change page
            document.removeEventListener('keydown', initPageNav)
            keyboardListener = false;

            // Init thebelab
            thebelab.bootstrap();

            // Remove copy buttons since they won't work anymore
            const copyAndThebeButtons = document.querySelectorAll('.copybtn, .thebebtn')
            copyAndThebeButtons.forEach((button, index) => {
                button.remove();
            });

            // Remove outputs since they'll be stale
            const outputs = document.querySelectorAll('.output *, .output')
            outputs.forEach((output, index) => {
                output.remove();
            });
        }

        // Add event listener for the function to modify code cells
        const thebelabButtons = document.querySelectorAll('[id^=thebelab], [id$=thebelab]')
        thebelabButtons.forEach((thebelabButton,index) => {
            if (thebelabButton === null) {
                setTimeout(initThebelab, 250)
                return
            };
            thebelabButton.addEventListener('click', addThebelabToCodeCells);
        });
    }

    // Initialize Thebelab
    initFunction(initThebelab);
</script>



  <!-- Load the auto-generating TOC -->
  <script src="/blog2/assets/js/tocbot.min.js"  type="text/javascript"></script>
  <script>
var initToc = function () {
  tocbot.init({
    tocSelector: 'nav.onthispage',
    contentSelector: '.c-textbook__content',
    headingSelector: 'h2, h3',
    orderedList: false,
    collapseDepth: 6,
    listClass: 'toc__menu',
    activeListItemClass: "",  // Not using
    activeLinkClass: "", // Not using
  });
  tocbot.refresh();
}
initFunction(initToc);
</script>

  <!-- Google analytics -->
  <script src="/blog2/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" async></script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const codeCellId = index => `codecell${index}`

const clipboardButton = id =>
  `<a id="copy-button-${id}" class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/blog2/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  const codeCells = document.querySelectorAll('div.c-textbook__content > div.highlighter-rouge > div.highlight > pre, div.input_area pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.getElementById("copy-button" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>


  <!-- Hide cell code -->
  
<script>
/**
Add buttons to hide code cells
*/


var setCodeCellVisibility = function(inputField, kind) {
    // Update the image and class for hidden
    var id = inputField.getAttribute('data-id');
    var codeCell = document.querySelector(`#${id} div.highlight`);

    if (kind === "visible") {
        codeCell.classList.remove('hidden');
        inputField.checked = true;
    } else {
        codeCell.classList.add('hidden');
        inputField.checked = false;
    }
}

var toggleCodeCellVisibility = function (event) {
    // The label is clicked, and now we decide what to do based on the input field's clicked status
    if (event.target.tagName === "LABEL") {
        var inputField = event.target.previousElementSibling;
    } else {
        // It is the span inside the target
        var inputField = event.target.parentElement.previousElementSibling;
    }

    if (inputField.checked === true) {
        setCodeCellVisibility(inputField, "visible");
    } else {
        setCodeCellVisibility(inputField, "hidden");
    }
}


// Button constructor
const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

var addHideButton = function () {
  // If a hide button is already added, don't add another
  if (document.querySelector('div.hidecode input') !== null) {
      return;
  }

  // Find the input cells and add a hide button
  document.querySelectorAll('div.input_area').forEach(function (item, index) {
    if (!item.classList.contains("hidecode")) {
        // Skip the cell if it doesn't have a hidecode class
        return;
    }

    const id = codeCellId(index)
    item.setAttribute('id', id);
    // Insert the button just inside the end of the next div
    item.querySelector('div').insertAdjacentHTML('beforeend', hideCodeButton(id))

    // Set up the visibility toggle
    hideLink = document.querySelector(`#${id} div.highlight + input + label`);
    hideLink.addEventListener('click', toggleCodeCellVisibility)
  });
}


// Initialize the hide buttos
var initHiddenCells = function () {
    // Add hide buttons to the cells
    addHideButton();

    // Toggle the code cells that should be hidden
    document.querySelectorAll('div.hidecode input').forEach(function (item) {
        setCodeCellVisibility(item, 'hidden');
        item.checked = true;
    })
}

initFunction(initHiddenCells);

</script>


  <!-- Load custom website scripts -->
  <script src="/blog2/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/blog2/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/blog2/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("https://1007530194.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="/blog2/assets/js/lunr/lunr.min.js" type="text/javascript"></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>
</head>

<body>
<!-- .js-show-sidebar shows sidebar by default -->
<div id="js-textbook" class="c-textbook js-show-sidebar">
    



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://jupyter.org/jupyter-book/intro.html"><img src="/blog2/assets/images/logo/logo.png" class="textbook_logo" id="sidebar-logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">MyBook</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/00Todo/index.html"
        >
          
            1.
          
          Todo
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/00Todo/00Todo.html"
                >
                  
                    1.1
                  
                  Todo
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/00Todo/Example.html"
                >
                  
                    1.2
                  
                  Example
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/00Todo/jupyter-book-start.html"
                >
                  
                    1.3
                  
                  jupyter-book-start
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/01TensorFlow/index.html"
        >
          
            2.
          
          TensorFlow
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/DNN%E5%AE%9E%E4%BE%8B%E4%BB%A3%E7%A0%81%E5%9D%97.html"
                >
                  
                    2.1
                  
                  DNN实例代码块
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/DSSM%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html"
                >
                  
                    2.2
                  
                  DSSM双塔模型
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/keras-RNN%E5%AE%9E%E4%BE%8B.html"
                >
                  
                    2.3
                  
                  keras-RNN实例
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/KerasExample/index.html"
                >
                  
                    2.4
                  
                  KerasExample
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/addition_rnn.html"
                    >
                      
                        2.4.1
                        
                      
                      addition_rnn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/antirectifier.html"
                    >
                      
                        2.4.2
                        
                      
                      antirectifier
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/babi_memnn.html"
                    >
                      
                        2.4.3
                        
                      
                      babi_memnn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/babi_rnn.html"
                    >
                      
                        2.4.4
                        
                      
                      babi_rnn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/image_ocr.html"
                    >
                      
                        2.4.5
                        
                      
                      image_ocr
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/imdb_bidirectional_lstm.html"
                    >
                      
                        2.4.6
                        
                      
                      imdb_bidirectional_lstm
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/imdb_cnn.html"
                    >
                      
                        2.4.7
                        
                      
                      imdb_cnn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/imdb_cnn_lstm.html"
                    >
                      
                        2.4.8
                        
                      
                      imdb_cnn_lstm
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/imdb_lstm.html"
                    >
                      
                        2.4.9
                        
                      
                      imdb_lstm
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/lstm-seq2seq.html"
                    >
                      
                        2.4.10
                        
                      
                      lstm-seq2seq
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/mnist_acgan.html"
                    >
                      
                        2.4.11
                        
                      
                      mnist_acgan
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/mnist_mlp.html"
                    >
                      
                        2.4.12
                        
                      
                      mnist_mlp
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/README.html"
                    >
                      
                        2.4.13
                        
                      
                      README
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/reuters_mlp.html"
                    >
                      
                        2.4.14
                        
                      
                      reuters_mlp
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/KerasExample/tensorboard_embeddings_mnist.html"
                    >
                      
                        2.4.15
                        
                      
                      tensorboard_embeddings_mnist
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/keras%E6%97%A5%E5%B8%B8%E5%B0%8F%E5%B7%A5%E5%85%B7.html"
                >
                  
                    2.5
                  
                  keras日常小工具
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/kera%E5%AD%A6%E4%B9%A0-%E6%9B%B4%E6%96%B0.html"
                >
                  
                    2.6
                  
                  kera学习-更新
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/kera%E5%AE%9E%E4%BE%8B%E4%BA%8C.html"
                >
                  
                    2.7
                  
                  kera实例二
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/recommendation/index.html"
                >
                  
                    2.8
                  
                  recommendation
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/recommendation/DeepFM%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5.html"
                    >
                      
                        2.8.1
                        
                      
                      DeepFM模型理论和实践
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/recommendation/DIN%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5.html"
                    >
                      
                        2.8.2
                        
                      
                      DIN模型理论和实践
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/recommendation/LR.html"
                    >
                      
                        2.8.3
                        
                      
                      LR
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/recommendation/MLR%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E5%92%8C%E5%AE%9E%E8%B7%B5.html"
                    >
                      
                        2.8.4
                        
                      
                      MLR模型理论和实践
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/01TensorFlow/tensorflowExample/index.html"
                >
                  
                    2.9
                  
                  tensorflowExample
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0001-ml_introduction.html"
                    >
                      
                        2.9.1
                        
                      
                      ml_introduction
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0002-mnist_dataset_intro.html"
                    >
                      
                        2.9.2
                        
                      
                      mnist_dataset_intro
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0101-helloworld.html"
                    >
                      
                        2.9.3
                        
                      
                      helloworld
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0102-basic_eager_api.html"
                    >
                      
                        2.9.4
                        
                      
                      basic_eager_api
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0103-basic_operations.html"
                    >
                      
                        2.9.5
                        
                      
                      basic_operations
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0201-linear_regression_eager_api.html"
                    >
                      
                        2.9.6
                        
                      
                      linear_regression_eager_api
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0202-linear_regression.html"
                    >
                      
                        2.9.7
                        
                      
                      linear_regression
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0203-logistic_regression_eager_api.html"
                    >
                      
                        2.9.8
                        
                      
                      logistic_regression_eager_api
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0204-nearest_neighbor.html"
                    >
                      
                        2.9.9
                        
                      
                      nearest_neighbor
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0205-kmeans.html"
                    >
                      
                        2.9.10
                        
                      
                      kmeans
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0206-LR.html"
                    >
                      
                        2.9.11
                        
                      
                      LR
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0207-GBDT.html"
                    >
                      
                        2.9.12
                        
                      
                      GBDT
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0208-word2vec.html"
                    >
                      
                        2.9.13
                        
                      
                      word2vec
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0209-random_forest.html"
                    >
                      
                        2.9.14
                        
                      
                      random_forest
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0301-autoencoder.html"
                    >
                      
                        2.9.15
                        
                      
                      autoencoder
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0302-bidirectional_rnn.html"
                    >
                      
                        2.9.16
                        
                      
                      bidirectional_rnn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0303-convolutional_network_raw.html"
                    >
                      
                        2.9.17
                        
                      
                      convolutional_network_raw
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0304-convolutional_network.html"
                    >
                      
                        2.9.18
                        
                      
                      convolutional_network
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0305-dcgan.html"
                    >
                      
                        2.9.19
                        
                      
                      dcgan
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0306-dynamic_rnn.html"
                    >
                      
                        2.9.20
                        
                      
                      dynamic_rnn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0307-gan.html"
                    >
                      
                        2.9.21
                        
                      
                      gan
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0308-neural_network_eager_api.html"
                    >
                      
                        2.9.22
                        
                      
                      neural_network_eager_api
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0309-neural_network_raw.html"
                    >
                      
                        2.9.23
                        
                      
                      neural_network_raw
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0310-neural_network.html"
                    >
                      
                        2.9.24
                        
                      
                      neural_network
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0311-recurrent_network.html"
                    >
                      
                        2.9.25
                        
                      
                      recurrent_network
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0312-variational_autoencoder.html"
                    >
                      
                        2.9.26
                        
                      
                      variational_autoencoder
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0401-save_restore_model.html"
                    >
                      
                        2.9.27
                        
                      
                      save_restore_model
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0402-tensorboard_advanced.html"
                    >
                      
                        2.9.28
                        
                      
                      tensorboard_advanced
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0403-tensorboard_basic.html"
                    >
                      
                        2.9.29
                        
                      
                      tensorboard_basic
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0501-build_an_image_dataset.html"
                    >
                      
                        2.9.30
                        
                      
                      build_an_image_dataset
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0502-tensorflow_dataset_api.html"
                    >
                      
                        2.9.31
                        
                      
                      tensorflow_dataset_api
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0601-multigpu_basics.html"
                    >
                      
                        2.9.32
                        
                      
                      multigpu_basics
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/01TensorFlow/tensorflowExample/0602-multigpu_cnn.html"
                    >
                      
                        2.9.33
                        
                      
                      multigpu_cnn
                    </a>
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/11ReadBook/index.html"
        >
          
            3.
          
          ReadBook
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/index.html"
                >
                  
                    3.1
                  
                  统计学习方法
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA.html"
                    >
                      
                        3.1.1
                        
                      
                      统计学习方法概论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/02%E6%84%9F%E7%9F%A5%E6%9C%BA.html"
                    >
                      
                        3.1.2
                        
                      
                      感知机
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/03k%E8%BF%91%E9%82%BB%E6%B3%95.html"
                    >
                      
                        3.1.3
                        
                      
                      k近邻法
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/04%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.html"
                    >
                      
                        3.1.4
                        
                      
                      朴素贝叶斯
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/05%E5%86%B3%E7%AD%96%E6%A0%91.html"
                    >
                      
                        3.1.5
                        
                      
                      决策树
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/06%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92.html"
                    >
                      
                        3.1.6
                        
                      
                      逻辑斯谛回归
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/07%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html"
                    >
                      
                        3.1.7
                        
                      
                      支持向量机
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/08%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95.html"
                    >
                      
                        3.1.8
                        
                      
                      提升方法
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/09%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF.html"
                    >
                      
                        3.1.9
                        
                      
                      算法及其推广
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/10%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html"
                    >
                      
                        3.1.10
                        
                      
                      隐马尔可夫模型
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/00%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/11%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html"
                    >
                      
                        3.1.11
                        
                      
                      条件随机场
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/02deep-learning-with-python/index.html"
                >
                  
                    3.2
                  
                  deep-learning-with-python
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/21-a-first-look-at-a-neural-network.html"
                    >
                      
                        3.2.1
                        
                      
                      a-first-look-at-a-neural-network
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/35-classifying-movie-reviews.html"
                    >
                      
                        3.2.2
                        
                      
                      classifying-movie-reviews
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/36-classifying-newswires.html"
                    >
                      
                        3.2.3
                        
                      
                      classifying-newswires
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/37-predicting-house-prices.html"
                    >
                      
                        3.2.4
                        
                      
                      predicting-house-prices
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/44-overfitting-and-underfitting.html"
                    >
                      
                        3.2.5
                        
                      
                      overfitting-and-underfitting
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/51-introduction-to-convnets.html"
                    >
                      
                        3.2.6
                        
                      
                      introduction-to-convnets
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/52-using-convnets-with-small-datasets.html"
                    >
                      
                        3.2.7
                        
                      
                      using-convnets-with-small-datasets
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/53-using-a-pretrained-convnet.html"
                    >
                      
                        3.2.8
                        
                      
                      using-a-pretrained-convnet
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/54-visualizing-what-convnets-learn.html"
                    >
                      
                        3.2.9
                        
                      
                      visualizing-what-convnets-learn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/61-one-hot-encoding-of-words-or-characters.html"
                    >
                      
                        3.2.10
                        
                      
                      one-hot-encoding-of-words-or-characters
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/61-using-word-embeddings.html"
                    >
                      
                        3.2.11
                        
                      
                      using-word-embeddings
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/62-understanding-recurrent-neural-networks.html"
                    >
                      
                        3.2.12
                        
                      
                      understanding-recurrent-neural-networks
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/63-advanced-usage-of-recurrent-neural-networks.html"
                    >
                      
                        3.2.13
                        
                      
                      advanced-usage-of-recurrent-neural-networks
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/64-sequence-processing-with-convnets.html"
                    >
                      
                        3.2.14
                        
                      
                      sequence-processing-with-convnets
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/81-text-generation-with-lstm.html"
                    >
                      
                        3.2.15
                        
                      
                      text-generation-with-lstm
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/82-deep-dream.html"
                    >
                      
                        3.2.16
                        
                      
                      deep-dream
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/83-neural-style-transfer.html"
                    >
                      
                        3.2.17
                        
                      
                      neural-style-transfer
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/84-generating-images-with-vaes.html"
                    >
                      
                        3.2.18
                        
                      
                      generating-images-with-vaes
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/02deep-learning-with-python/85-introduction-to-gans.html"
                    >
                      
                        3.2.19
                        
                      
                      introduction-to-gans
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/03handbook-en/index.html"
                >
                  
                    3.3
                  
                  handbook-en
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/000-Preface.html"
                    >
                      
                        3.3.1
                        
                      
                      Preface
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/200-Introduction-to-NumPy.html"
                    >
                      
                        3.3.2
                        
                      
                      Introduction-to-NumPy
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/201-Understanding-Data-Types.html"
                    >
                      
                        3.3.3
                        
                      
                      Understanding-Data-Types
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/202-The-Basics-Of-NumPy-Arrays.html"
                    >
                      
                        3.3.4
                        
                      
                      The-Basics-Of-NumPy-Arrays
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/203-Computation-on-arrays-ufuncs.html"
                    >
                      
                        3.3.5
                        
                      
                      Computation-on-arrays-ufuncs
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/204-Computation-on-arrays-aggregates.html"
                    >
                      
                        3.3.6
                        
                      
                      Computation-on-arrays-aggregates
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/205-Computation-on-arrays-broadcasting.html"
                    >
                      
                        3.3.7
                        
                      
                      Computation-on-arrays-broadcasting
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/206-Boolean-Arrays-and-Masks.html"
                    >
                      
                        3.3.8
                        
                      
                      Boolean-Arrays-and-Masks
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/207-Fancy-Indexing.html"
                    >
                      
                        3.3.9
                        
                      
                      Fancy-Indexing
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/208-Sorting.html"
                    >
                      
                        3.3.10
                        
                      
                      Sorting
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/209-Structured-Data-NumPy.html"
                    >
                      
                        3.3.11
                        
                      
                      Structured-Data-NumPy
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/300-Introduction-to-Pandas.html"
                    >
                      
                        3.3.12
                        
                      
                      Introduction-to-Pandas
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/301-Introducing-Pandas-Objects.html"
                    >
                      
                        3.3.13
                        
                      
                      Introducing-Pandas-Objects
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/302-Data-Indexing-and-Selection.html"
                    >
                      
                        3.3.14
                        
                      
                      Data-Indexing-and-Selection
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/303-Operations-in-Pandas.html"
                    >
                      
                        3.3.15
                        
                      
                      Operations-in-Pandas
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/304-Missing-Values.html"
                    >
                      
                        3.3.16
                        
                      
                      Missing-Values
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/305-Hierarchical-Indexing.html"
                    >
                      
                        3.3.17
                        
                      
                      Hierarchical-Indexing
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/306-Concat-And-Append.html"
                    >
                      
                        3.3.18
                        
                      
                      Concat-And-Append
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/307-Merge-and-Join.html"
                    >
                      
                        3.3.19
                        
                      
                      Merge-and-Join
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/308-Aggregation-and-Grouping.html"
                    >
                      
                        3.3.20
                        
                      
                      Aggregation-and-Grouping
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/309-Pivot-Tables.html"
                    >
                      
                        3.3.21
                        
                      
                      Pivot-Tables
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/310-Working-With-Strings.html"
                    >
                      
                        3.3.22
                        
                      
                      Working-With-Strings
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/311-Working-with-Time-Series.html"
                    >
                      
                        3.3.23
                        
                      
                      Working-with-Time-Series
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/312-Performance-Eval-and-Query.html"
                    >
                      
                        3.3.24
                        
                      
                      Performance-Eval-and-Query
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/313-Further-Resources.html"
                    >
                      
                        3.3.25
                        
                      
                      Further-Resources
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/400-Introduction-To-Matplotlib.html"
                    >
                      
                        3.3.26
                        
                      
                      Introduction-To-Matplotlib
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/401-Simple-Line-Plots.html"
                    >
                      
                        3.3.27
                        
                      
                      Simple-Line-Plots
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/402-Simple-Scatter-Plots.html"
                    >
                      
                        3.3.28
                        
                      
                      Simple-Scatter-Plots
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/403-Errorbars.html"
                    >
                      
                        3.3.29
                        
                      
                      Errorbars
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/404-Density-and-Contour-Plots.html"
                    >
                      
                        3.3.30
                        
                      
                      Density-and-Contour-Plots
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/405-Histograms-and-Binnings.html"
                    >
                      
                        3.3.31
                        
                      
                      Histograms-and-Binnings
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/406-Customizing-Legends.html"
                    >
                      
                        3.3.32
                        
                      
                      Customizing-Legends
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/407-Customizing-Colorbars.html"
                    >
                      
                        3.3.33
                        
                      
                      Customizing-Colorbars
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/408-Multiple-Subplots.html"
                    >
                      
                        3.3.34
                        
                      
                      Multiple-Subplots
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/409-Text-and-Annotation.html"
                    >
                      
                        3.3.35
                        
                      
                      Text-and-Annotation
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/410-Customizing-Ticks.html"
                    >
                      
                        3.3.36
                        
                      
                      Customizing-Ticks
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/411-Settings-and-Stylesheets.html"
                    >
                      
                        3.3.37
                        
                      
                      Settings-and-Stylesheets
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/412-Three-Dimensional-Plotting.html"
                    >
                      
                        3.3.38
                        
                      
                      Three-Dimensional-Plotting
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/413-Geographic-Data-With-Basemap.html"
                    >
                      
                        3.3.39
                        
                      
                      Geographic-Data-With-Basemap
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/414-Visualization-With-Seaborn.html"
                    >
                      
                        3.3.40
                        
                      
                      Visualization-With-Seaborn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/415-Further-Resources.html"
                    >
                      
                        3.3.41
                        
                      
                      Further-Resources
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/500-Machine-Learning.html"
                    >
                      
                        3.3.42
                        
                      
                      Machine-Learning
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/501-What-Is-Machine-Learning.html"
                    >
                      
                        3.3.43
                        
                      
                      What-Is-Machine-Learning
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/502-Introducing-Scikit-Learn.html"
                    >
                      
                        3.3.44
                        
                      
                      Introducing-Scikit-Learn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/503-Hyperparameters-and-Model-Validation.html"
                    >
                      
                        3.3.45
                        
                      
                      Hyperparameters-and-Model-Validation
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/504-Feature-Engineering.html"
                    >
                      
                        3.3.46
                        
                      
                      Feature-Engineering
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/505-Naive-Bayes.html"
                    >
                      
                        3.3.47
                        
                      
                      Naive-Bayes
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/506-Linear-Regression.html"
                    >
                      
                        3.3.48
                        
                      
                      Linear-Regression
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/507-Support-Vector-Machines.html"
                    >
                      
                        3.3.49
                        
                      
                      Support-Vector-Machines
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/508-Random-Forests.html"
                    >
                      
                        3.3.50
                        
                      
                      Random-Forests
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/509-Principal-Component-Analysis.html"
                    >
                      
                        3.3.51
                        
                      
                      Principal-Component-Analysis
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/510-Manifold-Learning.html"
                    >
                      
                        3.3.52
                        
                      
                      Manifold-Learning
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/511-K-Means.html"
                    >
                      
                        3.3.53
                        
                      
                      K-Means
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/512-Gaussian-Mixtures.html"
                    >
                      
                        3.3.54
                        
                      
                      Gaussian-Mixtures
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/513-Kernel-Density-Estimation.html"
                    >
                      
                        3.3.55
                        
                      
                      Kernel-Density-Estimation
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/514-Image-Features.html"
                    >
                      
                        3.3.56
                        
                      
                      Image-Features
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/515-Learning-More.html"
                    >
                      
                        3.3.57
                        
                      
                      Learning-More
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/600-Figure-Code.html"
                    >
                      
                        3.3.58
                        
                      
                      Figure-Code
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/handbook-en-01.html"
                    >
                      
                        3.3.59
                        
                      
                      handbook-en-01
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/handbook-en-02.html"
                    >
                      
                        3.3.60
                        
                      
                      handbook-en-02
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/Index.html"
                    >
                      
                        3.3.61
                        
                      
                      Index
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/merge_3.html"
                    >
                      
                        3.3.62
                        
                      
                      merge_3
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/merge_4.html"
                    >
                      
                        3.3.63
                        
                      
                      merge_4
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/03handbook-en/merge_5.html"
                    >
                      
                        3.3.64
                        
                      
                      merge_5
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/04MachineLearningPractice/index.html"
                >
                  
                    3.4
                  
                  MachineLearningPractice
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/00naive-bayes-discuss.html"
                    >
                      
                        3.4.1
                        
                      
                      naive-bayes-discuss
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/01%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.html"
                    >
                      
                        3.4.2
                        
                      
                      机器学习基础
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/02k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.html"
                    >
                      
                        3.4.3
                        
                      
                      k-近邻算法
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/03%E5%86%B3%E7%AD%96%E6%A0%91.html"
                    >
                      
                        3.4.4
                        
                      
                      决策树
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/04%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.html"
                    >
                      
                        3.4.5
                        
                      
                      朴素贝叶斯
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/05Logistic%E5%9B%9E%E5%BD%92.html"
                    >
                      
                        3.4.6
                        
                      
                      Logistic回归
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/06%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html"
                    >
                      
                        3.4.7
                        
                      
                      支持向量机
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/07%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%92%8CAdaBoost.html"
                    >
                      
                        3.4.8
                        
                      
                      集成方法-随机森林和AdaBoost
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/08%E9%A2%84%E6%B5%8B%E6%95%B0%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE-%E5%9B%9E%E5%BD%92.html"
                    >
                      
                        3.4.9
                        
                      
                      预测数值型数据-回归
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/09%E6%A0%91%E5%9B%9E%E5%BD%92.html"
                    >
                      
                        3.4.10
                        
                      
                      树回归
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/10k-means%E8%81%9A%E7%B1%BB.html"
                    >
                      
                        3.4.11
                        
                      
                      k-means聚类
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/11Apriori-%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90.html"
                    >
                      
                        3.4.12
                        
                      
                      Apriori-关联分析
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/12FP-growth-%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86.html"
                    >
                      
                        3.4.13
                        
                      
                      FP-growth-频繁项集
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/13%E5%88%A9%E7%94%A8PCA%E6%9D%A5%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE.html"
                    >
                      
                        3.4.14
                        
                      
                      利用PCA来简化数据
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/14%E5%88%A9%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE.html"
                    >
                      
                        3.4.15
                        
                      
                      利用SVD简化数据
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/15%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8EMapReduce.html"
                    >
                      
                        3.4.16
                        
                      
                      大数据与MapReduce
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/04MachineLearningPractice/16%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"
                    >
                      
                        3.4.17
                        
                      
                      推荐系统
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/05pydata-zh/index.html"
                >
                  
                    3.5
                  
                  pydata-zh
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/041%20%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%E5%AF%B9%E8%B1%A1.html"
                    >
                      
                        3.5.1
                        
                      
                      多维数组对象
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/042%20%E9%80%9A%E7%94%A8%E5%87%BD%E6%95%B0.html"
                    >
                      
                        3.5.2
                        
                      
                      通用函数
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/043%20%E6%95%B0%E7%BB%84%E5%AF%BC%E5%90%91%E7%BC%96%E7%A8%8B.html"
                    >
                      
                        3.5.3
                        
                      
                      数组导向编程
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/051%20pandas%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html"
                    >
                      
                        3.5.4
                        
                      
                      pandas的数据结构
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/052%20pandas%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD.html"
                    >
                      
                        3.5.5
                        
                      
                      pandas主要功能
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/053%20%E6%80%BB%E7%BB%93%E5%92%8C%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1.html"
                    >
                      
                        3.5.6
                        
                      
                      总结和描述性统计
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/071%20%E5%A4%84%E7%90%86%E7%BC%BA%E5%A4%B1%E6%95%B0%E6%8D%AE.html"
                    >
                      
                        3.5.7
                        
                      
                      处理缺失数据
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/072%20%E6%95%B0%E6%8D%AE%E5%8F%98%E6%8D%A2.html"
                    >
                      
                        3.5.8
                        
                      
                      数据变换
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/073%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86.html"
                    >
                      
                        3.5.9
                        
                      
                      字符串处理
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/111%20%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%85%B6%E5%B7%A5%E5%85%B7.html"
                    >
                      
                        3.5.10
                        
                      
                      日期和时间数据类型及其工具
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/112%20%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%9F%BA%E7%A1%80.html"
                    >
                      
                        3.5.11
                        
                      
                      时间序列基础
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/113%20%E6%97%A5%E6%9C%9F%E8%8C%83%E5%9B%B4,%E9%A2%91%E5%BA%A6,%E5%92%8C%E4%BD%8D%E7%A7%BB.html"
                    >
                      
                        3.5.12
                        
                      
                      日期范围，频度，和位移
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/121%20%E7%B1%BB%E5%88%AB%E6%95%B0%E6%8D%AE.html"
                    >
                      
                        3.5.13
                        
                      
                      类别数据
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/142%20MovieLens%201M%E6%95%B0%E6%8D%AE%E9%9B%86.html"
                    >
                      
                        3.5.14
                        
                      
                      MovieLens 1M数据集
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/11ReadBook/05pydata-zh/143%20%E4%BB%8E1880%E5%B9%B4%E8%87%B32010%E5%B9%B4%E7%BE%8E%E5%9B%BD%E5%A9%B4%E5%84%BF%E5%A7%93%E5%90%8D.html"
                    >
                      
                        3.5.15
                        
                      
                      从1880年至2010年美国婴儿姓名
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/11%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%96%87%E7%89%88.html"
                >
                  
                    3.6
                  
                  深度学习中文版
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/12spark-en%E6%B1%87%E6%80%BB.html"
                >
                  
                    3.7
                  
                  spark-en汇总
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/11ReadBook/51%E6%89%80%E8%B0%93%E6%83%85%E5%95%86%E9%AB%98,%E5%B0%B1%E6%98%AF%E4%BC%9A%E8%AF%B4%E8%AF%9D.html"
                >
                  
                    3.8
                  
                  所谓情商高，就是会说话
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/index.html"
        >
          
            4.
          
          常见算法
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/adaBoost/index.html"
                >
                  
                    4.1
                  
                  adaBoost
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/adaBoost/AdaBoost.html"
                    >
                      
                        4.1.1
                        
                      
                      AdaBoost
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/adaBoost/AdaBoost%E5%85%83%E7%AE%97%E6%B3%95%E6%8F%90%E9%AB%98%E5%88%86%E7%B1%BB%E6%80%A7%E8%83%BD.html"
                    >
                      
                        4.1.2
                        
                      
                      AdaBoost元算法提高分类性能
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/apriori/index.html"
                >
                  
                    4.2
                  
                  apriori
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/apriori/apriori.html"
                    >
                      
                        4.2.1
                        
                      
                      apriori
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/bayes/index.html"
                >
                  
                    4.3
                  
                  bayes
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/bayes/naiveBayes.html"
                    >
                      
                        4.3.1
                        
                      
                      naiveBayes
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/boost/index.html"
                >
                  
                    4.4
                  
                  boost
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/boost/Boost%E7%AE%80%E4%BB%8B.html"
                    >
                      
                        4.4.1
                        
                      
                      Boost简介
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/ES%E6%9F%A5%E8%AF%A2.html"
                >
                  
                    4.5
                  
                  ES查询
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/fp-growth/index.html"
                >
                  
                    4.6
                  
                  fp-growth
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/fp-growth/fp-growth.html"
                    >
                      
                        4.6.1
                        
                      
                      fp-growth
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/k-Nearest%20Neighbor/index.html"
                >
                  
                    4.7
                  
                  k-Nearest Neighbor
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/k-Nearest%20Neighbor/knn.html"
                    >
                      
                        4.7.1
                        
                      
                      knn
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/k-Nearest%20Neighbor/knn_%E5%8E%9F%E7%89%88.html"
                    >
                      
                        4.7.2
                        
                      
                      knn_原版
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/kmeans/index.html"
                >
                  
                    4.8
                  
                  kmeans
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/kmeans/kmeans.html"
                    >
                      
                        4.8.1
                        
                      
                      kmeans
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/line-regression/index.html"
                >
                  
                    4.9
                  
                  line-regression
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/line-regression/line_regression.html"
                    >
                      
                        4.9.1
                        
                      
                      line_regression
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/line-regression/LR.html"
                    >
                      
                        4.9.2
                        
                      
                      LR
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/logistic/index.html"
                >
                  
                    4.10
                  
                  logistic
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/logistic/logistic-code.html"
                    >
                      
                        4.10.1
                        
                      
                      logistic-code
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/logistic/logistic-%E7%90%86%E8%AE%BA.html"
                    >
                      
                        4.10.2
                        
                      
                      logistic-理论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/logistic/temo.html"
                    >
                      
                        4.10.3
                        
                      
                      temo
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/pca/index.html"
                >
                  
                    4.11
                  
                  pca
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/pca/pca.html"
                    >
                      
                        4.11.1
                        
                      
                      pca
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/pca%E4%B8%8Esvd%E7%9A%84%E6%AF%94%E8%BE%83/index.html"
                >
                  
                    4.12
                  
                  pca与svd的比较
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/pca%E4%B8%8Esvd%E7%9A%84%E6%AF%94%E8%BE%83/pca.html"
                    >
                      
                        4.12.1
                        
                      
                      pca
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/README.html"
                >
                  
                    4.13
                  
                  README
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/regressionTree/index.html"
                >
                  
                    4.14
                  
                  regressionTree
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/regressionTree/CART.html"
                    >
                      
                        4.14.1
                        
                      
                      CART
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/svd/index.html"
                >
                  
                    4.15
                  
                  svd
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/svd/collaborative_filter.html"
                    >
                      
                        4.15.1
                        
                      
                      collaborative_filter
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/svd/svd.html"
                    >
                      
                        4.15.2
                        
                      
                      svd
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/svm/index.html"
                >
                  
                    4.16
                  
                  svm
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/svm/smo.html"
                    >
                      
                        4.16.1
                        
                      
                      smo
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/Untitled.html"
                >
                  
                    4.17
                  
                  Untitled
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/xgboost/index.html"
                >
                  
                    4.18
                  
                  xgboost
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/xgboost/xgboost.html"
                    >
                      
                        4.18.1
                        
                      
                      xgboost
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/xgboost/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bxgboost.html"
                    >
                      
                        4.18.2
                        
                      
                      十分钟上手xgboost
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91(DecisionTree)/index.html"
                >
                  
                    4.19
                  
                  决策树(DecisionTree)
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91(DecisionTree)/decisionTree.html"
                    >
                      
                        4.19.1
                        
                      
                      decisionTree
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91(DecisionTree)/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%80%E4%BB%8B.html"
                    >
                      
                        4.19.2
                        
                      
                      决策树简介
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/%E5%BB%BA%E6%A8%A1%E8%BF%87%E7%A8%8B.html"
                >
                  
                    4.20
                  
                  建模过程
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/index.html"
        >
          
            5.
          
          算法集锦
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/math/index.html"
                >
                  
                    5.1
                  
                  math
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/math/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90.html"
                    >
                      
                        5.1.1
                        
                      
                      主成分分析
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/math/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95.html"
                    >
                      
                        5.1.2
                        
                      
                      最小二乘法
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/math/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC.html"
                    >
                      
                        5.1.3
                        
                      
                      矩阵求导
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/index.html"
                >
                  
                    5.2
                  
                  推荐算法
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93.html"
                    >
                      
                        5.2.1
                        
                      
                      协同过滤推荐算法总结
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html"
                    >
                      
                        5.2.2
                        
                      
                      矩阵分解
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/index.html"
                >
                  
                    5.3
                  
                  推荐系统
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/test.html"
                    >
                      
                        5.3.1
                        
                      
                      test
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/index.html"
                >
                  
                    5.4
                  
                  文本挖掘
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/LDA%E6%A8%A1%E5%9E%8B.html"
                    >
                      
                        5.4.1
                        
                      
                      LDA模型
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/Word2Vec.html"
                    >
                      
                        5.4.2
                        
                      
                      Word2Vec
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/%E6%96%87%E6%9C%AC%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E7%B4%A2%E5%BC%95(LSI).html"
                    >
                      
                        5.4.3
                        
                      
                      文本主题模型之潜在语义索引(LSI)
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E9%A2%84%E5%A4%84%E7%90%86%E4%B9%8BTF-IDF.html"
                    >
                      
                        5.4.4
                        
                      
                      文本挖掘预处理之TF-IDF
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8BHMM.html"
                    >
                      
                        5.4.5
                        
                      
                      隐马尔科夫模型HMM
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.html"
                >
                  
                    5.5
                  
                  深度学习
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LSTM.html"
                    >
                      
                        5.5.1
                        
                      
                      LSTM
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/RNN.html"
                    >
                      
                        5.5.2
                        
                      
                      RNN
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Seq2Seq.html"
                    >
                      
                        5.5.3
                        
                      
                      Seq2Seq
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86.html"
                    >
                      
                        5.5.4
                        
                      
                      TensorFlow-字符串处理
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tensorflow%E5%AD%A6%E4%B9%A0.html"
                    >
                      
                        5.5.5
                        
                      
                      tensorflow学习
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/TensorFlow%E5%B8%B8%E8%A7%81%E4%BB%A3%E7%A0%81%E5%9D%97.html"
                    >
                      
                        5.5.6
                        
                      
                      TensorFlow常见代码块
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tf%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95.html"
                    >
                      
                        5.5.7
                        
                      
                      tf优化方法
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tf%E5%87%BD%E6%95%B0.html"
                    >
                      
                        5.5.8
                        
                      
                      tf函数
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"
                    >
                      
                        5.5.9
                        
                      
                      人工神经网络
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html"
                >
                  
                    5.6
                  
                  神经网络
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/AutoEncoder-%E8%87%AA%E7%BC%96%E7%A0%81%E5%AE%9E%E8%B7%B5.html"
                    >
                      
                        5.6.1
                        
                      
                      AutoEncoder-自编码实践
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/AutoEncoder-%E8%87%AA%E7%BC%96%E7%A0%81%E7%90%86%E8%AE%BA.html"
                    >
                      
                        5.6.2
                        
                      
                      AutoEncoder-自编码理论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html"
                    >
                      
                        5.6.3
                        
                      
                      CNN-卷积神经网络理论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/DNN-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"
                    >
                      
                        5.6.4
                        
                      
                      DNN-深度神经网络
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/LSTM-%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html"
                    >
                      
                        5.6.5
                        
                      
                      LSTM-长短期记忆网络理论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/PCA-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90.html"
                    >
                      
                        5.6.6
                        
                      
                      PCA-主成分分析
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RBM-%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA%E5%AE%9E%E8%B7%B5.html"
                    >
                      
                        5.6.7
                        
                      
                      RBM-受限玻尔兹曼机实践
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RBM-%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA%E7%90%86%E8%AE%BA.html"
                    >
                      
                        5.6.8
                        
                      
                      RBM-受限玻尔兹曼机理论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RNN-%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA.html"
                    >
                      
                        5.6.9
                        
                      
                      RNN-递归神经网络理论
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%90%91%E9%87%8F%E9%99%8D%E7%BB%B4.html"
                    >
                      
                        5.6.10
                        
                      
                      向量降维
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB.html"
                    >
                      
                        5.6.11
                        
                      
                      常见损失函数汇总
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/14%E7%AE%97%E6%B3%95%E9%9B%86%E9%94%A6/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%B8%B8%E8%A7%81%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB.html"
                    >
                      
                        5.6.12
                        
                      
                      常见激励函数汇总
                    </a>
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/15tools/index.html"
        >
          
            6.
          
          tools
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/15tools/colabHub/index.html"
                >
                  
                    6.1
                  
                  colabHub
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/colabHub/README.html"
                    >
                      
                        6.1.1
                        
                      
                      README
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/colabHub/%E5%88%9D%E5%A7%8B%E5%8C%96.html"
                    >
                      
                        6.1.2
                        
                      
                      初始化
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/15tools/DownLoadPicture.html"
                >
                  
                    6.2
                  
                  DownLoadPicture
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/15tools/latex/index.html"
                >
                  
                    6.3
                  
                  latex
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/latex/LaTeX%E5%85%AC%E5%BC%8F%E5%AE%9E%E4%BE%8B.html"
                    >
                      
                        6.3.1
                        
                      
                      LaTeX公式实例
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/latex/latex%E5%85%AC%E5%BC%8F%E7%BC%96%E5%8F%B7.html"
                    >
                      
                        6.3.2
                        
                      
                      latex公式编号
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/latex/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8BLaTeX.html"
                    >
                      
                        6.3.3
                        
                      
                      十分钟上手LaTeX
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/15tools/numpy/index.html"
                >
                  
                    6.4
                  
                  numpy
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/numpy/numpy%E6%95%99%E7%A8%8B00.html"
                    >
                      
                        6.4.1
                        
                      
                      numpy教程00
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/numpy/numpy%E6%95%99%E7%A8%8B01.html"
                    >
                      
                        6.4.2
                        
                      
                      numpy教程01
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/numpy/numpy%E6%95%99%E7%A8%8B02.html"
                    >
                      
                        6.4.3
                        
                      
                      numpy教程02
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/numpy/numpy%E6%95%99%E7%A8%8B03.html"
                    >
                      
                        6.4.4
                        
                      
                      numpy教程03
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/15tools/pandas/index.html"
                >
                  
                    6.5
                  
                  pandas
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/pandas.html"
                    >
                      
                        6.5.1
                        
                      
                      pandas
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/pandas%E5%87%BD%E6%95%B0%E6%B7%B1%E5%85%A5.html"
                    >
                      
                        6.5.2
                        
                      
                      pandas函数深入
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/pandas%E6%95%99%E7%A8%8B01.html"
                    >
                      
                        6.5.3
                        
                      
                      pandas教程01
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/pandas%E6%95%99%E7%A8%8B02.html"
                    >
                      
                        6.5.4
                        
                      
                      pandas教程02
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/pandas%E6%95%99%E7%A8%8B03.html"
                    >
                      
                        6.5.5
                        
                      
                      pandas教程03
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8BPandas.html"
                    >
                      
                        6.5.6
                        
                      
                      十分钟上手Pandas
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/pandas/%E5%8D%81%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8BPandas%E5%87%BD%E6%95%B0.html"
                    >
                      
                        6.5.7
                        
                      
                      十分钟上手Pandas函数
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/15tools/%E7%94%BB%E5%9B%BE/index.html"
                >
                  
                    6.6
                  
                  画图
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bfolium%E5%9C%B0%E5%9B%BE.html"
                    >
                      
                        6.6.1
                        
                      
                      python画图之folium地图
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-3D%E5%9B%BE.html"
                    >
                      
                        6.6.2
                        
                      
                      python画图之pycharts-3D图
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-kline.html"
                    >
                      
                        6.6.3
                        
                      
                      python画图之pycharts-kline
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-%E5%85%B6%E4%BB%96.html"
                    >
                      
                        6.6.4
                        
                      
                      python画图之pycharts-其他
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-%E5%85%B6%E4%BB%96%E5%9D%90%E6%A0%87%E7%B3%BB.html"
                    >
                      
                        6.6.5
                        
                      
                      python画图之pycharts-其他坐标系
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-%E5%9C%B0%E5%9B%BE.html"
                    >
                      
                        6.6.6
                        
                      
                      python画图之pycharts-地图
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-%E7%9B%B4%E8%A7%92%E5%9D%90%E6%A0%87%E7%B3%BB.html"
                    >
                      
                        6.6.7
                        
                      
                      python画图之pycharts-直角坐标系
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/python%E7%94%BB%E5%9B%BE%E4%B9%8Bpycharts-%E7%AE%80%E4%BB%8B.html"
                    >
                      
                        6.6.8
                        
                      
                      python画图之pycharts-简介
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/15tools/%E7%94%BB%E5%9B%BE/Untitled.html"
                    >
                      
                        6.6.9
                        
                      
                      Untitled
                    </a>
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/99Example/index.html"
        >
          
            7.
          
          Example
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/4/index.html"
                >
                  
                    7.1
                  
                  
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/computational-tools.html"
                    >
                      
                        7.1.1
                        
                      
                      computational-tools
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/endnote.html"
                    >
                      
                        7.1.2
                        
                      
                      endnote
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/establishing-causality.html"
                    >
                      
                        7.1.3
                        
                      
                      establishing-causality
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/intro.html"
                    >
                      
                        7.1.4
                        
                      
                      intro
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/observation-and-visualization-john-snow-and-the-broad-street-pump.html"
                    >
                      
                        7.1.5
                        
                      
                      observation-and-visualization-john-snow-and-the-broad-street-pump
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/Plotting_the_Classics.html"
                    >
                      
                        7.1.6
                        
                      
                      Plotting_the_Classics
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/randomization.html"
                    >
                      
                        7.1.7
                        
                      
                      randomization
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/snow-s-grand-experiment.html"
                    >
                      
                        7.1.8
                        
                      
                      snow-s-grand-experiment
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/subsections.html"
                    >
                      
                        7.1.9
                        
                      
                      subsections
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/subsectiontwo.html"
                    >
                      
                        7.1.10
                        
                      
                      subsectiontwo
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/4/why-data-science.html"
                    >
                      
                        7.1.11
                        
                      
                      why-data-science
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Calls.html"
                >
                  
                    7.2
                  
                  Calls
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/causality-and-experiments.html"
                >
                  
                    7.3
                  
                  causality-and-experiments
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Expressions.html"
                >
                  
                    7.4
                  
                  Expressions
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/features/index.html"
                >
                  
                    7.5
                  
                  features
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/citations.html"
                    >
                      
                        7.5.1
                        
                      
                      citations
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/features.html"
                    >
                      
                        7.5.2
                        
                      
                      features
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/hiding.html"
                    >
                      
                        7.5.3
                        
                      
                      hiding
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/interact.html"
                    >
                      
                        7.5.4
                        
                      
                      interact
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/interactive_cells.html"
                    >
                      
                        7.5.5
                        
                      
                      interactive_cells
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/limits.html"
                    >
                      
                        7.5.6
                        
                      
                      limits
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/markdown.html"
                    >
                      
                        7.5.7
                        
                      
                      markdown
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/notebooks.html"
                    >
                      
                        7.5.8
                        
                      
                      notebooks
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/features/search.html"
                    >
                      
                        7.5.9
                        
                      
                      search
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Growth.html"
                >
                  
                    7.6
                  
                  Growth
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/guide/index.html"
                >
                  
                    7.7
                  
                  guide
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/guide/01_overview.html"
                    >
                      
                        7.7.1
                        
                      
                      _overview
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/guide/02_create.html"
                    >
                      
                        7.7.2
                        
                      
                      _create
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/guide/03_build.html"
                    >
                      
                        7.7.3
                        
                      
                      _build
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/guide/04_faq.html"
                    >
                      
                        7.7.4
                        
                      
                      _faq
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/99Example/guide/05_advanced.html"
                    >
                      
                        7.7.5
                        
                      
                      _advanced
                    </a>
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Introduction_to_Tables.html"
                >
                  
                    7.8
                  
                  Introduction_to_Tables
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Names.html"
                >
                  
                    7.9
                  
                  Names
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Numbers.html"
                >
                  
                    7.10
                  
                  Numbers
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/programming-in-python.html"
                >
                  
                    7.11
                  
                  programming-in-python
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/statistical-techniques.html"
                >
                  
                    7.12
                  
                  statistical-techniques
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Strings.html"
                >
                  
                    7.13
                  
                  Strings
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/Types.html"
                >
                  
                    7.14
                  
                  Types
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/99Example/what-is-data-science.html"
                >
                  
                    7.15
                  
                  what-is-data-science
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/notebooks/index.html"
        >
          
            8.
          
          notebooks
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/notebooks/JupyterNotebookTips.html"
                >
                  
                    8.1
                  
                  JupyterNotebookTips
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/notebooks/LinearRegression.html"
                >
                  
                    8.2
                  
                  LinearRegression
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/notechats/index.html"
        >
          
            9.
          
          notechats
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/notechats/notedata%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE.html"
                >
                  
                    9.1
                  
                  notedata测试数据
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/package/index.html"
        >
          
            10.
          
          package
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/package/folium.html"
                >
                  
                    10.1
                  
                  folium
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/package/graphviz%E4%B9%8B%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8.html"
                >
                  
                    10.2
                  
                  graphviz之安装使用
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/package/pygithub.html"
                >
                  
                    10.3
                  
                  pygithub
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/package/word2vec.html"
                >
                  
                    10.4
                  
                  word2vec
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/package/%E5%90%91%E9%87%8F%E5%BC%95%E6%93%8Efaiss.html"
                >
                  
                    10.5
                  
                  向量引擎faiss
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/package/%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83.html"
                >
                  
                    10.6
                  
                  词向量训练
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/blog2/papers/index.html"
        >
          
            11.
          
          papers
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/blog2/papers/atrank/index.html"
                >
                  
                    11.1
                  
                  atrank
                </a>

                
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/papers/atrank/Atrank.html"
                    >
                      
                        11.1.1
                        
                      
                      Atrank
                    </a>
                
                  
                  

                  <li class="c-sidebar__subsection">
                    <a class="c-sidebar__entry "
                      href="/blog2/papers/atrank/Attention.html"
                    >
                      
                        11.1.2
                        
                      
                      Attention
                    </a>
                

              </li>
              
            
          </ul>
        
      </li>

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

    
    <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
    <aside class="sidebar__right">
        <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
        <nav class="onthispage">
        </nav>
    </aside>
    
    <main class="c-textbook__page" tabindex="-1">
        <div class="o-wrapper">
            <div class="c-sidebar-toggle">
  <!-- We show the sidebar by default so we use .is-active -->
  <button
    id="js-sidebar-toggle"
    class="hamburger hamburger--arrowalt is-active"
  >
    <span class="hamburger-box">
      <span class="hamburger-inner"></span>
    </span>
    <span class="c-sidebar-toggle__label">Toggle Sidebar</span>
  </button>
</div>

            

            <div class="c-textbook__content">
                <h1 id="第4章-基于概率论的分类方法朴素贝叶斯">第4章 基于概率论的分类方法：朴素贝叶斯</h1>

<h2 id="朴素贝叶斯-概述">朴素贝叶斯 概述</h2>

<p><code class="highlighter-rouge">贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。本章首先介绍贝叶斯分类算法的基础——贝叶斯定理。最后，我们通过实例来讨论贝叶斯分类的中最简单的一种: 朴素贝叶斯分类。</code></p>

<h2 id="贝叶斯理论--条件概率">贝叶斯理论 &amp; 条件概率</h2>

<h3 id="贝叶斯理论">贝叶斯理论</h3>

<p>我们现在有一个数据集，它由两类数据组成，数据分布如下图所示：</p>

<p><img src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/朴素贝叶斯示例数据分布.png" alt="朴素贝叶斯示例数据分布" title="参数已知的概率分布" /></p>

<p>我们现在用 p1(x,y) 表示数据点 (x,y) 属于类别 1（图中用圆点表示的类别）的概率，用 p2(x,y) 表示数据点 (x,y) 属于类别 2（图中三角形表示的类别）的概率，那么对于一个新数据点 (x,y)，可以用下面的规则来判断它的类别：</p>
<ul>
  <li>如果 p1(x,y) &gt; p2(x,y) ，那么类别为1</li>
  <li>如果 p2(x,y) &gt; p1(x,y) ，那么类别为2</li>
</ul>

<p>也就是说，我们会选择高概率对应的类别。这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。</p>

<h3 id="条件概率">条件概率</h3>

<table>
  <tbody>
    <tr>
      <td>如果你对 p(x,y</td>
      <td>c1) 符号很熟悉，那么可以跳过本小节。</td>
    </tr>
  </tbody>
</table>

<p>有一个装了 7 块石头的罐子，其中 3 块是白色的，4 块是黑色的。如果从罐子中随机取出一块石头，那么是白色石头的可能性是多少？由于取石头有 7 种可能，其中 3 种为白色，所以取出白色石头的概率为 3/7 。那么取到黑色石头的概率又是多少呢？很显然，是 4/7 。我们使用 P(white) 来表示取到白色石头的概率，其概率值可以通过白色石头数目除以总的石头数目来得到。</p>

<p><img src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/NB_2.png" alt="包含 7 块石头的集合" /></p>

<p>如果这 7 块石头如下图所示，放在两个桶中，那么上述概率应该如何计算？</p>

<p><img src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/NB_3.png" alt="7块石头放入两个桶中" /></p>

<table>
  <tbody>
    <tr>
      <td>计算 P(white) 或者 P(black) ，如果事先我们知道石头所在桶的信息是会改变结果的。这就是所谓的条件概率（conditional probablity）。假定计算的是从 B 桶取到白色石头的概率，这个概率可以记作 P(white</td>
      <td>bucketB) ，我们称之为“在已知石头出自 B 桶的条件下，取出白色石头的概率”。很容易得到，P(white</td>
      <td>bucketA) 值为 2/4 ，P(white</td>
      <td>bucketB) 的值为 1/3 。</td>
    </tr>
  </tbody>
</table>

<p>条件概率的计算公式如下：</p>

<table>
  <tbody>
    <tr>
      <td>P(white</td>
      <td>bucketB) = P(white and bucketB) / P(bucketB)</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>首先，我们用 B 桶中白色石头的个数除以两个桶中总的石头数，得到 P(white and bucketB) = 1/7 .其次，由于 B 桶中有 3 块石头，而总石头数为 7 ，于是 P(bucketB) 就等于 3/7 。于是又 P(white</td>
      <td>bucketB) = P(white and bucketB) / P(bucketB) = (1/7) / (3/7) = 1/3 。</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>另外一种有效计算条件概率的方法称为贝叶斯准则。贝叶斯准则告诉我们如何交换条件概率中的条件与结果，即如果已知 P(x</td>
      <td>c)，要求 P(c</td>
      <td>x)，那么可以使用下面的计算方法：</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>![计算p(c</td>
      <td>x)的方法](/assets/images/4.NaiveBayesian/NB_4.png)</td>
    </tr>
  </tbody>
</table>

<h3 id="使用条件概率来分类">使用条件概率来分类</h3>

<p>上面我们提到贝叶斯决策理论要求计算两个概率 p1(x, y) 和 p2(x, y):</p>
<ul>
  <li>如果 p1(x, y) &gt; p2(x, y), 那么属于类别 1;</li>
  <li>如果 p2(x, y) &gt; p1(X, y), 那么属于类别 2.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>这并不是贝叶斯决策理论的所有内容。使用 p1() 和 p2() 只是为了尽可能简化描述，而真正需要计算和比较的是 p(c1</td>
      <td>x, y) 和 p(c2</td>
      <td>x, y) .这些符号所代表的具体意义是: 给定某个由 x、y 表示的数据点，那么该数据点来自类别 c1 的概率是多少？数据点来自类别 c2 的概率又是多少？注意这些概率与概率 p(x, y</td>
      <td>c1) 并不一样，不过可以使用贝叶斯准则来交换概率中条件与结果。具体地，应用贝叶斯准则得到:</td>
    </tr>
  </tbody>
</table>

<p><img src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/NB_5.png" alt="应用贝叶斯准则" /></p>

<p>使用上面这些定义，可以定义贝叶斯分类准则为:</p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>如果 P(c1</td>
          <td>x, y) &gt; P(c2</td>
          <td>x, y), 那么属于类别 c1;</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>如果 P(c2</td>
          <td>x, y) &gt; P(c1</td>
          <td>x, y), 那么属于类别 c2.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p>在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。</p>

<p>我们假设特征之间  <strong>相互独立</strong> 。所谓 <b>独立(independence)</b> 指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系，比如说，“我们”中的“我”和“们”出现的概率与这两个字相邻没有任何关系。这个假设正是朴素贝叶斯分类器中 朴素(naive) 一词的含义。朴素贝叶斯分类器中的另一个假设是，<b>每个特征同等重要</b>。</p>

<p><b>Note:</b> 朴素贝叶斯分类器通常有两种实现方式: 一种基于伯努利模型实现，一种基于多项式模型实现。这里采用前一种实现方式。该实现方式中并不考虑词在文档中出现的次数，只考虑出不出现，因此在这个意义上相当于假设词是等权重的。</p>

<h2 id="朴素贝叶斯-场景">朴素贝叶斯 场景</h2>

<p>机器学习的一个重要应用就是文档的自动分类。</p>

<p>在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。</p>

<p>朴素贝叶斯是上面介绍的贝叶斯分类器的一个扩展，是用于文档分类的常用算法。下面我们会进行一些朴素贝叶斯分类的实践项目。</p>

<h2 id="朴素贝叶斯-原理">朴素贝叶斯 原理</h2>

<h3 id="朴素贝叶斯-工作原理">朴素贝叶斯 工作原理</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>提取所有文档中的词条并进行去重
获取文档的所有类别
计算每个类别中的文档数目
对每篇训练文档: 
    对每个类别: 
        如果词条出现在文档中--&gt;增加该词条的计数值（for循环或者矩阵相加）
        增加所有词条的计数值（此类别下词条总数）
对每个类别: 
    对每个词条: 
        将该词条的数目除以总词条数目得到的条件概率（P(词条|类别)）
返回该文档属于每个类别的条件概率（P(类别|文档的所有词条)）
</code></pre></div></div>

<h3 id="朴素贝叶斯-开发流程">朴素贝叶斯 开发流程</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>收集数据: 可以使用任何方法。
准备数据: 需要数值型或者布尔型数据。
分析数据: 有大量特征时，绘制特征作用不大，此时使用直方图效果更好。
训练算法: 计算不同的独立特征的条件概率。
测试算法: 计算错误率。
使用算法: 一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。
</code></pre></div></div>

<h3 id="朴素贝叶斯-算法特点">朴素贝叶斯 算法特点</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>优点: 在数据较少的情况下仍然有效，可以处理多类别问题。
缺点: 对于输入数据的准备方式较为敏感。
适用数据类型: 标称型数据。
</code></pre></div></div>

<h2 id="朴素贝叶斯-项目案例">朴素贝叶斯 项目案例</h2>

<h3 id="项目案例1-屏蔽社区留言板的侮辱性言论">项目案例1: 屏蔽社区留言板的侮辱性言论</h3>

<h4 id="项目概述">项目概述</h4>

<p>构建一个快速过滤器来屏蔽在线社区留言板上的侮辱性言论。如果某条留言使用了负面或者侮辱性的语言，那么就将该留言标识为内容不当。对此问题建立两个类别: 侮辱类和非侮辱类，使用 1 和 0 分别表示。</p>

<h4 id="开发流程">开发流程</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>收集数据: 可以使用任何方法
准备数据: 从文本中构建词向量
分析数据: 检查词条确保解析的正确性
训练算法: 从词向量计算概率
测试算法: 根据现实情况修改分类器
使用算法: 对社区留言板言论进行分类
</code></pre></div></div>

<blockquote>
  <p>收集数据: 可以使用任何方法</p>
</blockquote>

<p>本例是我们自己构造的词表:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loadDataSet</span><span class="p">():</span>
    <span class="s">"""
    创建数据集
    :return: 单词列表postingList, 所属类别classVec
    """</span>
    <span class="n">postingList</span> <span class="o">=</span> <span class="p">[[</span><span class="s">'my'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'has'</span><span class="p">,</span> <span class="s">'flea'</span><span class="p">,</span> <span class="s">'problems'</span><span class="p">,</span> <span class="s">'help'</span><span class="p">,</span> <span class="s">'please'</span><span class="p">],</span> <span class="c">#[0,0,1,1,1......]</span>
                   <span class="p">[</span><span class="s">'maybe'</span><span class="p">,</span> <span class="s">'not'</span><span class="p">,</span> <span class="s">'take'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">,</span> <span class="s">'to'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'park'</span><span class="p">,</span> <span class="s">'stupid'</span><span class="p">],</span>
                   <span class="p">[</span><span class="s">'my'</span><span class="p">,</span> <span class="s">'dalmation'</span><span class="p">,</span> <span class="s">'is'</span><span class="p">,</span> <span class="s">'so'</span><span class="p">,</span> <span class="s">'cute'</span><span class="p">,</span> <span class="s">'I'</span><span class="p">,</span> <span class="s">'love'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">],</span>
                   <span class="p">[</span><span class="s">'stop'</span><span class="p">,</span> <span class="s">'posting'</span><span class="p">,</span> <span class="s">'stupid'</span><span class="p">,</span> <span class="s">'worthless'</span><span class="p">,</span> <span class="s">'garbage'</span><span class="p">],</span>
                   <span class="p">[</span><span class="s">'mr'</span><span class="p">,</span> <span class="s">'licks'</span><span class="p">,</span> <span class="s">'ate'</span><span class="p">,</span> <span class="s">'my'</span><span class="p">,</span> <span class="s">'steak'</span><span class="p">,</span> <span class="s">'how'</span><span class="p">,</span> <span class="s">'to'</span><span class="p">,</span> <span class="s">'stop'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">],</span>
                   <span class="p">[</span><span class="s">'quit'</span><span class="p">,</span> <span class="s">'buying'</span><span class="p">,</span> <span class="s">'worthless'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'food'</span><span class="p">,</span> <span class="s">'stupid'</span><span class="p">]]</span>
    <span class="n">classVec</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c"># 1 is abusive, 0 not</span>
    <span class="k">return</span> <span class="n">postingList</span><span class="p">,</span> <span class="n">classVec</span>
</code></pre></div></div>

<blockquote>
  <p>准备数据: 从文本中构建词向量</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">createVocabList</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
    <span class="s">"""
    获取所有单词的集合
    :param dataSet: 数据集
    :return: 所有单词的集合(即不含重复元素的单词列表)
    """</span>
    <span class="n">vocabSet</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([])</span>  <span class="c"># create empty set</span>
    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span>
        <span class="c"># 操作符 | 用于求两个集合的并集</span>
        <span class="n">vocabSet</span> <span class="o">=</span> <span class="n">vocabSet</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>  <span class="c"># union of the two sets</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocabSet</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">setOfWords2Vec</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">inputSet</span><span class="p">):</span>
    <span class="s">"""
    遍历查看该单词是否出现，出现该单词则将该单词置1
    :param vocabList: 所有单词集合列表
    :param inputSet: 输入数据集
    :return: 匹配列表[0,1,0,1...]，其中 1与0 表示词汇表中的单词是否出现在输入的数据集中
    """</span>
    <span class="c"># 创建一个和词汇表等长的向量，并将其元素都设置为0</span>
    <span class="n">returnVec</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabList</span><span class="p">)</span><span class="c"># [0,0......]</span>
    <span class="c"># 遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">inputSet</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span>
            <span class="n">returnVec</span><span class="p">[</span><span class="n">vocabList</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">"the word: </span><span class="si">%</span><span class="s">s is not in my Vocabulary!"</span> <span class="o">%</span> <span class="n">word</span>
    <span class="k">return</span> <span class="n">returnVec</span>
</code></pre></div></div>

<blockquote>
  <p>分析数据: 检查词条确保解析的正确性</p>
</blockquote>

<p>检查函数执行情况，检查词表，不出现重复单词，需要的话，可以对其进行排序。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">listOPosts</span><span class="p">,</span> <span class="n">listClasses</span> <span class="o">=</span> <span class="n">bayes</span><span class="o">.</span><span class="n">loadDataSet</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">myVocabList</span> <span class="o">=</span> <span class="n">bayes</span><span class="o">.</span><span class="n">createVocabList</span><span class="p">(</span><span class="n">listOPosts</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">myVocabList</span>
<span class="p">[</span><span class="s">'cute'</span><span class="p">,</span> <span class="s">'love'</span><span class="p">,</span> <span class="s">'help'</span><span class="p">,</span> <span class="s">'garbage'</span><span class="p">,</span> <span class="s">'quit'</span><span class="p">,</span> <span class="s">'I'</span><span class="p">,</span> <span class="s">'problems'</span><span class="p">,</span> <span class="s">'is'</span><span class="p">,</span> <span class="s">'park'</span><span class="p">,</span> 
<span class="s">'stop'</span><span class="p">,</span> <span class="s">'flea'</span><span class="p">,</span> <span class="s">'dalmation'</span><span class="p">,</span> <span class="s">'licks'</span><span class="p">,</span> <span class="s">'food'</span><span class="p">,</span> <span class="s">'not'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">,</span> <span class="s">'buying'</span><span class="p">,</span> <span class="s">'posting'</span><span class="p">,</span> <span class="s">'has'</span><span class="p">,</span> <span class="s">'worthless'</span><span class="p">,</span> <span class="s">'ate'</span><span class="p">,</span> <span class="s">'to'</span><span class="p">,</span> <span class="s">'maybe'</span><span class="p">,</span> <span class="s">'please'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'how'</span><span class="p">,</span> 
<span class="s">'stupid'</span><span class="p">,</span> <span class="s">'so'</span><span class="p">,</span> <span class="s">'take'</span><span class="p">,</span> <span class="s">'mr'</span><span class="p">,</span> <span class="s">'steak'</span><span class="p">,</span> <span class="s">'my'</span><span class="p">]</span>
</code></pre></div></div>

<p>检查函数有效性。例如：myVocabList 中索引为 2 的元素是什么单词？应该是是 help 。该单词在第一篇文档中出现了，现在检查一下看看它是否出现在第四篇文档中。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">bayes</span><span class="o">.</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">listOPosts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">bayes</span><span class="o">.</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">listOPosts</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<blockquote>
  <p>训练算法: 从词向量计算概率</p>
</blockquote>

<p>现在已经知道了一个词是否出现在一篇文档中，也知道该文档所属的类别。接下来我们重写贝叶斯准则，将之前的 x, y 替换为 <b>w</b>. 粗体的 <b>w</b> 表示这是一个向量，即它由多个值组成。在这个例子中，数值个数与词汇表中的词个数相同。</p>

<p><img src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/NB_6.png" alt="重写贝叶斯准则" /></p>

<p>我们使用上述公式，对每个类计算该值，然后比较这两个概率值的大小。</p>

<table>
  <tbody>
    <tr>
      <td>首先可以通过类别 i (侮辱性留言或者非侮辱性留言)中的文档数除以总的文档数来计算概率 p(ci) 。接下来计算 p(<b>w</b></td>
      <td>ci) ，这里就要用到朴素贝叶斯假设。如果将 w 展开为一个个独立特征，那么就可以将上述概率写作 p(w0, w1, w2…wn</td>
      <td>ci) 。这里假设所有词都互相独立，该假设也称作条件独立性假设（例如 A 和 B 两个人抛骰子，概率是互不影响的，也就是相互独立的，A 抛 2点的同时 B 抛 3 点的概率就是 1/6 * 1/6），它意味着可以使用 p(w0</td>
      <td>ci)p(w1</td>
      <td>ci)p(w2</td>
      <td>ci)…p(wn</td>
      <td>ci) 来计算上述概率，这样就极大地简化了计算的过程。</td>
    </tr>
  </tbody>
</table>

<p>朴素贝叶斯分类器训练函数</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_trainNB0</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="n">trainCategory</span><span class="p">):</span>
    <span class="s">"""
    训练数据原版
    :param trainMatrix: 文件单词矩阵 [[1,0,1,1,1....],[],[]...]
    :param trainCategory: 文件对应的类别[0,1,1,0....]，列表长度等于单词矩阵数，其中的1代表对应的文件是侮辱性文件，0代表不是侮辱性矩阵
    :return:
    """</span>
    <span class="c"># 文件数</span>
    <span class="n">numTrainDocs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">)</span>
    <span class="c"># 单词数</span>
    <span class="n">numWords</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c"># 侮辱性文件的出现概率，即trainCategory中所有的1的个数，</span>
    <span class="c"># 代表的就是多少个侮辱性文件，与文件的总数相除就得到了侮辱性文件的出现概率</span>
    <span class="n">pAbusive</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainCategory</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">)</span>
    <span class="c"># 构造单词出现次数列表</span>
    <span class="n">p0Num</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span> <span class="c"># [0,0,0,.....]</span>
    <span class="n">p1Num</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span> <span class="c"># [0,0,0,.....]</span>

    <span class="c"># 整个数据集单词出现总数</span>
    <span class="n">p0Denom</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">p1Denom</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">):</span>
        <span class="c"># 是否是侮辱性文件</span>
        <span class="k">if</span> <span class="n">trainCategory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c"># 如果是侮辱性文件，对侮辱性文件的向量进行加和</span>
            <span class="n">p1Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c">#[0,1,1,....] + [0,1,1,....]-&gt;[0,2,2,...]</span>
            <span class="c"># 对向量中的所有元素进行求和，也就是计算所有侮辱性文件中出现的单词总数</span>
            <span class="n">p1Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p0Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">p0Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c"># 类别1，即侮辱性文档的[P(F1|C1),P(F2|C1),P(F3|C1),P(F4|C1),P(F5|C1)....]列表</span>
    <span class="c"># 即 在1类别下，每个单词出现的概率</span>
    <span class="n">p1Vect</span> <span class="o">=</span> <span class="n">p1Num</span> <span class="o">/</span> <span class="n">p1Denom</span><span class="c"># [1,2,3,5]/90-&gt;[1/90,...]</span>
    <span class="c"># 类别0，即正常文档的[P(F1|C0),P(F2|C0),P(F3|C0),P(F4|C0),P(F5|C0)....]列表</span>
    <span class="c"># 即 在0类别下，每个单词出现的概率</span>
    <span class="n">p0Vect</span> <span class="o">=</span> <span class="n">p0Num</span> <span class="o">/</span> <span class="n">p0Denom</span>
    <span class="k">return</span> <span class="n">p0Vect</span><span class="p">,</span> <span class="n">p1Vect</span><span class="p">,</span> <span class="n">pAbusive</span>
</code></pre></div></div>

<blockquote>
  <p>测试算法: 根据现实情况修改分类器</p>
</blockquote>

<table>
  <tbody>
    <tr>
      <td>在利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算 p(w0</td>
      <td>1) * p(w1</td>
      <td>1) * p(w2</td>
      <td>1)。如果其中一个概率值为 0，那么最后的乘积也为 0。为降低这种影响，可以将所有词的出现数初始化为 1，并将分母初始化为 2 （取1 或 2 的目的主要是为了保证分子和分母不为0，大家可以根据业务需求进行更改）。</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>另一个遇到的问题是下溢出，这是由于太多很小的数相乘造成的。当计算乘积 p(w0</td>
      <td>ci) * p(w1</td>
      <td>ci) * p(w2</td>
      <td>ci)… p(wn</td>
      <td>ci) 时，由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。（用 Python 尝试相乘许多很小的数，最后四舍五入后会得到 0）。一种解决办法是对乘积取自然对数。在代数中有 ln(a * b) = ln(a) + ln(b), 于是通过求对数可以避免下溢出或者浮点数舍入导致的错误。同时，采用自然对数进行处理不会有任何损失。</td>
    </tr>
  </tbody>
</table>

<p>下图给出了函数 f(x) 与 ln(f(x)) 的曲线。可以看出，它们在相同区域内同时增加或者减少，并且在相同点上取到极值。它们的取值虽然不同，但不影响最终结果。</p>

<p><img src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/NB_7.png" alt="函数图像" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">trainNB0</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="n">trainCategory</span><span class="p">):</span>
    <span class="s">"""
    训练数据优化版本
    :param trainMatrix: 文件单词矩阵
    :param trainCategory: 文件对应的类别
    :return:
    """</span>
    <span class="c"># 总文件数</span>
    <span class="n">numTrainDocs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">)</span>
    <span class="c"># 总单词数</span>
    <span class="n">numWords</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c"># 侮辱性文件的出现概率</span>
    <span class="n">pAbusive</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainCategory</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">)</span>
    <span class="c"># 构造单词出现次数列表</span>
    <span class="c"># p0Num 正常的统计</span>
    <span class="c"># p1Num 侮辱的统计</span>
    <span class="n">p0Num</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span><span class="c">#[0,0......]-&gt;[1,1,1,1,1.....]</span>
    <span class="n">p1Num</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span>

    <span class="c"># 整个数据集单词出现总数，2.0根据样本/实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整）</span>
    <span class="c"># p0Denom 正常的统计</span>
    <span class="c"># p1Denom 侮辱的统计</span>
    <span class="n">p0Denom</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">p1Denom</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">trainCategory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c"># 累加辱骂词的频次</span>
            <span class="n">p1Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="c"># 对每篇文章的辱骂的频次 进行统计汇总</span>
            <span class="n">p1Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p0Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">p0Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c"># 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表</span>
    <span class="n">p1Vect</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">p1Num</span> <span class="o">/</span> <span class="n">p1Denom</span><span class="p">)</span>
    <span class="c"># 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表</span>
    <span class="n">p0Vect</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">p0Num</span> <span class="o">/</span> <span class="n">p0Denom</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p0Vect</span><span class="p">,</span> <span class="n">p1Vect</span><span class="p">,</span> <span class="n">pAbusive</span>

</code></pre></div></div>

<blockquote>
  <p>使用算法: 对社区留言板言论进行分类</p>
</blockquote>

<p>朴素贝叶斯分类函数</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">classifyNB</span><span class="p">(</span><span class="n">vec2Classify</span><span class="p">,</span> <span class="n">p0Vec</span><span class="p">,</span> <span class="n">p1Vec</span><span class="p">,</span> <span class="n">pClass1</span><span class="p">):</span>
    <span class="s">"""
    使用算法：
        # 将乘法转换为加法
        乘法：P(C|F1F2...Fn) = P(F1F2...Fn|C)P(C)/P(F1F2...Fn)
        加法：P(F1|C)*P(F2|C)....P(Fn|C)P(C) -&gt; log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C))
    :param vec2Classify: 待测数据[0,1,1,1,1...]，即要分类的向量
    :param p0Vec: 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表
    :param p1Vec: 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表
    :param pClass1: 类别1，侮辱性文件的出现概率
    :return: 类别1 or 0
    """</span>
    <span class="c"># 计算公式  log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C))</span>
    <span class="c"># 大家可能会发现，上面的计算公式，没有除以贝叶斯准则的公式的分母，也就是 P(w) （P(w) 指的是此文档在所有的文档中出现的概率）就进行概率大小的比较了，</span>
    <span class="c"># 因为 P(w) 针对的是包含侮辱和非侮辱的全部文档，所以 P(w) 是相同的。</span>
    <span class="c"># 使用 NumPy 数组来计算两个向量相乘的结果，这里的相乘是指对应元素相乘，即先将两个向量中的第一个元素相乘，然后将第2个元素相乘，以此类推。</span>
    <span class="c"># 我的理解是：这里的 vec2Classify * p1Vec 的意思就是将每个词与其对应的概率相关联起来</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">vec2Classify</span> <span class="o">*</span> <span class="n">p1Vec</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span><span class="n">pClass1</span><span class="p">)</span> <span class="c"># P(w|c1) * P(c1) ，即贝叶斯准则的分子</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">vec2Classify</span> <span class="o">*</span> <span class="n">p0Vec</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">pClass1</span><span class="p">)</span> <span class="c"># P(w|c0) * P(c0) ，即贝叶斯准则的分子·</span>
    <span class="k">if</span> <span class="n">p1</span> <span class="o">&gt;</span> <span class="n">p0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>


<span class="k">def</span> <span class="nf">testingNB</span><span class="p">():</span>
    <span class="s">"""
    测试朴素贝叶斯算法
    """</span>
    <span class="c"># 1. 加载数据集</span>
    <span class="n">listOPosts</span><span class="p">,</span> <span class="n">listClasses</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">()</span>
    <span class="c"># 2. 创建单词集合</span>
    <span class="n">myVocabList</span> <span class="o">=</span> <span class="n">createVocabList</span><span class="p">(</span><span class="n">listOPosts</span><span class="p">)</span>
    <span class="c"># 3. 计算单词是否出现并创建数据矩阵</span>
    <span class="n">trainMat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">postinDoc</span> <span class="ow">in</span> <span class="n">listOPosts</span><span class="p">:</span>
        <span class="c"># 返回m*len(myVocabList)的矩阵， 记录的都是0，1信息</span>
        <span class="n">trainMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">postinDoc</span><span class="p">))</span>
    <span class="c"># 4. 训练数据</span>
    <span class="n">p0V</span><span class="p">,</span> <span class="n">p1V</span><span class="p">,</span> <span class="n">pAb</span> <span class="o">=</span> <span class="n">trainNB0</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">trainMat</span><span class="p">),</span> <span class="n">array</span><span class="p">(</span><span class="n">listClasses</span><span class="p">))</span>
    <span class="c"># 5. 测试数据</span>
    <span class="n">testEntry</span> <span class="o">=</span> <span class="p">[</span><span class="s">'love'</span><span class="p">,</span> <span class="s">'my'</span><span class="p">,</span> <span class="s">'dalmation'</span><span class="p">]</span>
    <span class="n">thisDoc</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">testEntry</span><span class="p">))</span>
    <span class="k">print</span> <span class="n">testEntry</span><span class="p">,</span> <span class="s">'classified as: '</span><span class="p">,</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">thisDoc</span><span class="p">,</span> <span class="n">p0V</span><span class="p">,</span> <span class="n">p1V</span><span class="p">,</span> <span class="n">pAb</span><span class="p">)</span>
    <span class="n">testEntry</span> <span class="o">=</span> <span class="p">[</span><span class="s">'stupid'</span><span class="p">,</span> <span class="s">'garbage'</span><span class="p">]</span>
    <span class="n">thisDoc</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">testEntry</span><span class="p">))</span>
    <span class="k">print</span> <span class="n">testEntry</span><span class="p">,</span> <span class="s">'classified as: '</span><span class="p">,</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">thisDoc</span><span class="p">,</span> <span class="n">p0V</span><span class="p">,</span> <span class="n">p1V</span><span class="p">,</span> <span class="n">pAb</span><span class="p">)</span>
</code></pre></div></div>

<p><a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py</a></p>

<h3 id="项目案例2-使用朴素贝叶斯过滤垃圾邮件">项目案例2: 使用朴素贝叶斯过滤垃圾邮件</h3>

<h4 id="项目概述-1">项目概述</h4>

<p>完成朴素贝叶斯的一个最著名的应用: 电子邮件垃圾过滤。</p>

<h4 id="开发流程-1">开发流程</h4>

<p>使用朴素贝叶斯对电子邮件进行分类</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>收集数据: 提供文本文件
准备数据: 将文本文件解析成词条向量
分析数据: 检查词条确保解析的正确性
训练算法: 使用我们之前建立的 trainNB() 函数
测试算法: 使用朴素贝叶斯进行交叉验证
使用算法: 构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上
</code></pre></div></div>

<blockquote>
  <p>收集数据: 提供文本文件</p>
</blockquote>

<p>文本文件内容如下:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hi Peter,

With Jose out of town, do you want to
meet once in a while to keep things
going and do some interesting stuff?

Let me know
Eugene
</code></pre></div></div>

<blockquote>
  <p>准备数据: 将文本文件解析成词条向量</p>
</blockquote>

<p>使用正则表达式来切分文本</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">mySent</span> <span class="o">=</span> <span class="s">'This book is the best book on Python or M.L. I have ever laid eyes upon.'</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">re</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">regEx</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="s">'</span><span class="se">\\</span><span class="s">W*'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">listOfTokens</span> <span class="o">=</span> <span class="n">regEx</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">mySent</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">listOfTokens</span>
<span class="p">[</span><span class="s">'This'</span><span class="p">,</span> <span class="s">'book'</span><span class="p">,</span> <span class="s">'is'</span><span class="p">,</span> <span class="s">'the'</span><span class="p">,</span> <span class="s">'best'</span><span class="p">,</span> <span class="s">'book'</span><span class="p">,</span> <span class="s">'on'</span><span class="p">,</span> <span class="s">'Python'</span><span class="p">,</span> <span class="s">'or'</span><span class="p">,</span> <span class="s">'M.L.'</span><span class="p">,</span> <span class="s">'I'</span><span class="p">,</span> <span class="s">'have'</span><span class="p">,</span> <span class="s">'ever'</span><span class="p">,</span> <span class="s">'laid'</span><span class="p">,</span> <span class="s">'eyes'</span><span class="p">,</span> <span class="s">'upon'</span><span class="p">,</span> <span class="s">''</span><span class="p">]</span>
</code></pre></div></div>

<blockquote>
  <p>分析数据: 检查词条确保解析的正确性</p>
</blockquote>

<blockquote>
  <p>训练算法: 使用我们之前建立的 trainNB0() 函数</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">trainNB0</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="n">trainCategory</span><span class="p">):</span>
    <span class="s">"""
    训练数据优化版本
    :param trainMatrix: 文件单词矩阵
    :param trainCategory: 文件对应的类别
    :return:
    """</span>
    <span class="c"># 总文件数</span>
    <span class="n">numTrainDocs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">)</span>
    <span class="c"># 总单词数</span>
    <span class="n">numWords</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c"># 侮辱性文件的出现概率</span>
    <span class="n">pAbusive</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainCategory</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">)</span>
    <span class="c"># 构造单词出现次数列表</span>
    <span class="c"># p0Num 正常的统计</span>
    <span class="c"># p1Num 侮辱的统计</span>
    <span class="n">p0Num</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span><span class="c">#[0,0......]-&gt;[1,1,1,1,1.....]</span>
    <span class="n">p1Num</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span>

    <span class="c"># 整个数据集单词出现总数，2.0根据样本/实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整）</span>
    <span class="c"># p0Denom 正常的统计</span>
    <span class="c"># p1Denom 侮辱的统计</span>
    <span class="n">p0Denom</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">p1Denom</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">trainCategory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c"># 累加辱骂词的频次</span>
            <span class="n">p1Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="c"># 对每篇文章的辱骂的频次 进行统计汇总</span>
            <span class="n">p1Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p0Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">p0Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c"># 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表</span>
    <span class="n">p1Vect</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">p1Num</span> <span class="o">/</span> <span class="n">p1Denom</span><span class="p">)</span>
    <span class="c"># 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表</span>
    <span class="n">p0Vect</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">p0Num</span> <span class="o">/</span> <span class="n">p0Denom</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p0Vect</span><span class="p">,</span> <span class="n">p1Vect</span><span class="p">,</span> <span class="n">pAbusive</span>
</code></pre></div></div>

<blockquote>
  <p>测试算法: 使用朴素贝叶斯进行交叉验证</p>
</blockquote>

<p>文件解析及完整的垃圾邮件测试函数</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 切分文本</span>
<span class="k">def</span> <span class="nf">textParse</span><span class="p">(</span><span class="n">bigString</span><span class="p">):</span>
    <span class="s">'''
    Desc:
        接收一个大字符串并将其解析为字符串列表
    Args:
        bigString -- 大字符串
    Returns:
        去掉少于 2 个字符的字符串，并将所有字符串转换为小写，返回字符串列表
    '''</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="c"># 使用正则表达式来切分句子，其中分隔符是除单词、数字外的任意字符串</span>
    <span class="n">listOfTokens</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">r'\W*'</span><span class="p">,</span> <span class="n">bigString</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">listOfTokens</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">spamTest</span><span class="p">():</span>
    <span class="s">'''
    Desc:
        对贝叶斯垃圾邮件分类器进行自动化处理。
    Args:
        none
    Returns:
        对测试集中的每封邮件进行分类，若邮件分类错误，则错误数加 1，最后返回总的错误百分比。
    '''</span>
    <span class="n">docList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">classList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fullText</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">26</span><span class="p">):</span>
        <span class="c"># 切分，解析数据，并归类为 1 类别</span>
        <span class="n">wordList</span> <span class="o">=</span> <span class="n">textParse</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">'input/4.NaiveBayes/email/spam/</span><span class="si">%</span><span class="s">d.txt'</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="n">docList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">classList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c"># 切分，解析数据，并归类为 0 类别</span>
        <span class="n">wordList</span> <span class="o">=</span> <span class="n">textParse</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">'input/4.NaiveBayes/email/ham/</span><span class="si">%</span><span class="s">d.txt'</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="n">docList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">fullText</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">classList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c"># 创建词汇表    </span>
    <span class="n">vocabList</span> <span class="o">=</span> <span class="n">createVocabList</span><span class="p">(</span><span class="n">docList</span><span class="p">)</span>
    <span class="n">trainingSet</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">testSet</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c"># 随机取 10 个邮件用来测试</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="c"># random.uniform(x, y) 随机生成一个范围为 x - y 的实数</span>
        <span class="n">randIndex</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">)))</span>
        <span class="n">testSet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
        <span class="k">del</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
    <span class="n">trainMat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">trainClasses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">docIndex</span> <span class="ow">in</span> <span class="n">trainingSet</span><span class="p">:</span>
        <span class="n">trainMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">docList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">]))</span>
        <span class="n">trainClasses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">])</span>
    <span class="n">p0V</span><span class="p">,</span> <span class="n">p1V</span><span class="p">,</span> <span class="n">pSpam</span> <span class="o">=</span> <span class="n">trainNB0</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">trainMat</span><span class="p">),</span> <span class="n">array</span><span class="p">(</span><span class="n">trainClasses</span><span class="p">))</span>
    <span class="n">errorCount</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">docIndex</span> <span class="ow">in</span> <span class="n">testSet</span><span class="p">:</span>
        <span class="n">wordVector</span> <span class="o">=</span> <span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">docList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">wordVector</span><span class="p">),</span> <span class="n">p0V</span><span class="p">,</span> <span class="n">p1V</span><span class="p">,</span> <span class="n">pSpam</span><span class="p">)</span> <span class="o">!=</span> <span class="n">classList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">]:</span>
            <span class="n">errorCount</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">print</span> <span class="s">'the errorCount is: '</span><span class="p">,</span> <span class="n">errorCount</span>
    <span class="k">print</span> <span class="s">'the testSet length is :'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">testSet</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">'the error rate is :'</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">errorCount</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testSet</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p>使用算法: 构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上</p>
</blockquote>

<p><a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py</a></p>

<h3 id="项目案例3-使用朴素贝叶斯分类器从个人广告中获取区域倾向">项目案例3: 使用朴素贝叶斯分类器从个人广告中获取区域倾向</h3>

<h4 id="项目概述-2">项目概述</h4>

<p>广告商往往想知道关于一个人的一些特定人口统计信息，以便能更好地定向推销广告。</p>

<p>我们将分别从美国的两个城市中选取一些人，通过分析这些人发布的信息，来比较这两个城市的人们在广告用词上是否不同。如果结论确实不同，那么他们各自常用的词是那些，从人们的用词当中，我们能否对不同城市的人所关心的内容有所了解。</p>

<h4 id="开发流程-2">开发流程</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>收集数据: 从 RSS 源收集内容，这里需要对 RSS 源构建一个接口
准备数据: 将文本文件解析成词条向量
分析数据: 检查词条确保解析的正确性
训练算法: 使用我们之前建立的 trainNB0() 函数
测试算法: 观察错误率，确保分类器可用。可以修改切分程序，以降低错误率，提高分类结果
使用算法: 构建一个完整的程序，封装所有内容。给定两个 RSS 源，改程序会显示最常用的公共词
</code></pre></div></div>

<blockquote>
  <p>收集数据: 从 RSS 源收集内容，这里需要对 RSS 源构建一个接口</p>
</blockquote>

<p>也就是导入 RSS 源，我们使用 python 下载文本，在http://code.google.com/p/feedparser/ 下浏览相关文档，安装 feedparse，首先解压下载的包，并将当前目录切换到解压文件所在的文件夹，然后在 python 提示符下输入：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</code></pre></div></div>

<blockquote>
  <p>准备数据: 将文本文件解析成词条向量</p>
</blockquote>

<p>文档词袋模型</p>

<p>我们将每个词的出现与否作为一个特征，这可以被描述为 <b>词集模型(set-of-words model)</b>。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这种方法被称为 <b>词袋模型(bag-of-words model)</b>。在词袋中，每个单词可以出现多次，而在词集中，每个词只能出现一次。为适应词袋模型，需要对函数 setOfWords2Vec() 稍加修改，修改后的函数为 bagOfWords2Vec() 。</p>

<p>如下给出了基于词袋模型的朴素贝叶斯代码。它与函数 setOfWords2Vec() 几乎完全相同，唯一不同的是每当遇到一个单词时，它会增加词向量中的对应值，而不只是将对应的数值设为 1 。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bagOfWords2VecMN</span><span class="p">(</span><span class="n">vocaList</span><span class="p">,</span> <span class="n">inputSet</span><span class="p">):</span>
    <span class="n">returnVec</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabList</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">inputSet</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">inputSet</span><span class="p">:</span>
            <span class="n">returnVec</span><span class="p">[</span><span class="n">vocabList</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">returnVec</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#创建一个包含在所有文档中出现的不重复词的列表</span>
<span class="k">def</span> <span class="nf">createVocabList</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
    <span class="n">vocabSet</span><span class="o">=</span><span class="nb">set</span><span class="p">([])</span>    <span class="c">#创建一个空集</span>
    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span>
        <span class="n">vocabSet</span><span class="o">=</span><span class="n">vocabSet</span><span class="o">|</span><span class="nb">set</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>   <span class="c">#创建两个集合的并集</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocabSet</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setOfWords2VecMN</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span><span class="n">inputSet</span><span class="p">):</span>
    <span class="n">returnVec</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabList</span><span class="p">)</span>  <span class="c">#创建一个其中所含元素都为0的向量</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">inputSet</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span>
                <span class="n">returnVec</span><span class="p">[</span><span class="n">vocabList</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">returnVec</span>

<span class="c">#文件解析</span>
<span class="k">def</span> <span class="nf">textParse</span><span class="p">(</span><span class="n">bigString</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="n">listOfTokens</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">r'\W*'</span><span class="p">,</span><span class="n">bigString</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">listOfTokens</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">2</span><span class="p">]</span>
</code></pre></div></div>

<blockquote>
  <p>分析数据: 检查词条确保解析的正确性</p>
</blockquote>

<blockquote>
  <p>训练算法: 使用我们之前建立的 trainNB0() 函数</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">trainNB0</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="n">trainCategory</span><span class="p">):</span>
    <span class="s">"""
    训练数据优化版本
    :param trainMatrix: 文件单词矩阵
    :param trainCategory: 文件对应的类别
    :return:
    """</span>
    <span class="c"># 总文件数</span>
    <span class="n">numTrainDocs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">)</span>
    <span class="c"># 总单词数</span>
    <span class="n">numWords</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c"># 侮辱性文件的出现概率</span>
    <span class="n">pAbusive</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainCategory</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">)</span>
    <span class="c"># 构造单词出现次数列表</span>
    <span class="c"># p0Num 正常的统计</span>
    <span class="c"># p1Num 侮辱的统计 </span>
    <span class="c"># 避免单词列表中的任何一个单词为0，而导致最后的乘积为0，所以将每个单词的出现次数初始化为 1</span>
    <span class="n">p0Num</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span><span class="c">#[0,0......]-&gt;[1,1,1,1,1.....]</span>
    <span class="n">p1Num</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span>

    <span class="c"># 整个数据集单词出现总数，2.0根据样本/实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整）</span>
    <span class="c"># p0Denom 正常的统计</span>
    <span class="c"># p1Denom 侮辱的统计</span>
    <span class="n">p0Denom</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">p1Denom</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">trainCategory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c"># 累加辱骂词的频次</span>
            <span class="n">p1Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="c"># 对每篇文章的辱骂的频次 进行统计汇总</span>
            <span class="n">p1Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p0Num</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">p0Denom</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c"># 类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表</span>
    <span class="n">p1Vect</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">p1Num</span> <span class="o">/</span> <span class="n">p1Denom</span><span class="p">)</span>
    <span class="c"># 类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表</span>
    <span class="n">p0Vect</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">p0Num</span> <span class="o">/</span> <span class="n">p0Denom</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p0Vect</span><span class="p">,</span> <span class="n">p1Vect</span><span class="p">,</span> <span class="n">pAbusive</span>
</code></pre></div></div>

<blockquote>
  <p>测试算法: 观察错误率，确保分类器可用。可以修改切分程序，以降低错误率，提高分类结果</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#RSS源分类器及高频词去除函数</span>
<span class="k">def</span> <span class="nf">calcMostFreq</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span><span class="n">fullText</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">operator</span>
    <span class="n">freqDict</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span>  <span class="c">#遍历词汇表中的每个词</span>
        <span class="n">freqDict</span><span class="p">[</span><span class="n">token</span><span class="p">]</span><span class="o">=</span><span class="n">fullText</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>  <span class="c">#统计每个词在文本中出现的次数</span>
    <span class="n">sortedFreq</span><span class="o">=</span><span class="nb">sorted</span><span class="p">(</span><span class="n">freqDict</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(),</span><span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c">#根据每个词出现的次数从高到底对字典进行排序</span>
    <span class="k">return</span> <span class="n">sortedFreq</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>   <span class="c">#返回出现次数最高的30个单词</span>
<span class="k">def</span> <span class="nf">localWords</span><span class="p">(</span><span class="n">feed1</span><span class="p">,</span><span class="n">feed0</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">feedparser</span>
    <span class="n">docList</span><span class="o">=</span><span class="p">[];</span><span class="n">classList</span><span class="o">=</span><span class="p">[];</span><span class="n">fullText</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">minLen</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feed1</span><span class="p">[</span><span class="s">'entries'</span><span class="p">]),</span><span class="nb">len</span><span class="p">(</span><span class="n">feed0</span><span class="p">[</span><span class="s">'entries'</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">minLen</span><span class="p">):</span>
        <span class="n">wordList</span><span class="o">=</span><span class="n">textParse</span><span class="p">(</span><span class="n">feed1</span><span class="p">[</span><span class="s">'entries'</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s">'summary'</span><span class="p">])</span>   <span class="c">#每次访问一条RSS源</span>
        <span class="n">docList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">fullText</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">classList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">wordList</span><span class="o">=</span><span class="n">textParse</span><span class="p">(</span><span class="n">feed0</span><span class="p">[</span><span class="s">'entries'</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s">'summary'</span><span class="p">])</span>
        <span class="n">docList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">fullText</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">classList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">vocabList</span><span class="o">=</span><span class="n">createVocabList</span><span class="p">(</span><span class="n">docList</span><span class="p">)</span>
    <span class="n">top30Words</span><span class="o">=</span><span class="n">calcMostFreq</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span><span class="n">fullText</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pairW</span> <span class="ow">in</span> <span class="n">top30Words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pairW</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span><span class="n">vocabList</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">pairW</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>    <span class="c">#去掉出现次数最高的那些词</span>
    <span class="n">trainingSet</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">minLen</span><span class="p">);</span><span class="n">testSet</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
        <span class="n">randIndex</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">)))</span>
        <span class="n">testSet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
        <span class="k">del</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
    <span class="n">trainMat</span><span class="o">=</span><span class="p">[];</span><span class="n">trainClasses</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">docIndex</span> <span class="ow">in</span> <span class="n">trainingSet</span><span class="p">:</span>
        <span class="n">trainMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bagOfWords2VecMN</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span><span class="n">docList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">]))</span>
        <span class="n">trainClasses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">])</span>
    <span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pSpam</span><span class="o">=</span><span class="n">trainNBO</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">trainMat</span><span class="p">),</span><span class="n">array</span><span class="p">(</span><span class="n">trainClasses</span><span class="p">))</span>
    <span class="n">errorCount</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">docIndex</span> <span class="ow">in</span> <span class="n">testSet</span><span class="p">:</span>
        <span class="n">wordVector</span><span class="o">=</span><span class="n">bagOfWords2VecMN</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span><span class="n">docList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">wordVector</span><span class="p">),</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pSpam</span><span class="p">)</span><span class="o">!=</span><span class="n">classList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">]:</span>
            <span class="n">errorCount</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">print</span> <span class="s">'the error rate is:'</span><span class="p">,</span><span class="nb">float</span><span class="p">(</span><span class="n">errorCount</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testSet</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vocabList</span><span class="p">,</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span>

<span class="c">#朴素贝叶斯分类函数</span>
<span class="k">def</span> <span class="nf">classifyNB</span><span class="p">(</span><span class="n">vec2Classify</span><span class="p">,</span><span class="n">p0Vec</span><span class="p">,</span><span class="n">p1Vec</span><span class="p">,</span><span class="n">pClass1</span><span class="p">):</span>
    <span class="n">p1</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">vec2Classify</span><span class="o">*</span><span class="n">p1Vec</span><span class="p">)</span><span class="o">+</span><span class="n">log</span><span class="p">(</span><span class="n">pClass1</span><span class="p">)</span>
    <span class="n">p0</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">vec2Classify</span><span class="o">*</span><span class="n">p0Vec</span><span class="p">)</span><span class="o">+</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">pClass1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p1</span><span class="o">&gt;</span><span class="n">p0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</code></pre></div></div>

<blockquote>
  <p>使用算法: 构建一个完整的程序，封装所有内容。给定两个 RSS 源，改程序会显示最常用的公共词</p>
</blockquote>

<p>函数 localWords() 使用了两个 RSS 源作为参数，RSS 源要在函数外导入，这样做的原因是 RSS 源会随时间而改变，重新加载 RSS 源就会得到新的数据</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">reload</span><span class="p">(</span><span class="n">bayes</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">module</span> <span class="s">'bayes'</span> <span class="k">from</span> <span class="s">'bayes.pyc'</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">feedparser</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ny</span><span class="o">=</span><span class="n">feedparser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s">'http://newyork.craigslist.org/stp/index.rss'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sy</span><span class="o">=</span><span class="n">feedparser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s">'http://sfbay.craigslist.org/stp/index.rss'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vocabList</span><span class="p">,</span><span class="n">pSF</span><span class="p">,</span><span class="n">pNY</span><span class="o">=</span><span class="n">bayes</span><span class="o">.</span><span class="n">localWords</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span><span class="n">sf</span><span class="p">)</span>
<span class="n">the</span> <span class="n">error</span> <span class="n">rate</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vocabList</span><span class="p">,</span><span class="n">pSF</span><span class="p">,</span><span class="n">pNY</span><span class="o">=</span><span class="n">bayes</span><span class="o">.</span><span class="n">localWords</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span><span class="n">sf</span><span class="p">)</span>
<span class="n">the</span> <span class="n">error</span> <span class="n">rate</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vocabList</span><span class="p">,</span><span class="n">pSF</span><span class="p">,</span><span class="n">pNY</span><span class="o">=</span><span class="n">bayes</span><span class="o">.</span><span class="n">localWords</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span><span class="n">sf</span><span class="p">)</span>
<span class="n">the</span> <span class="n">error</span> <span class="n">rate</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.55</span>
</code></pre></div></div>
<p>为了得到错误率的精确估计，应该多次进行上述实验，然后取平均值</p>

<p>接下来，我们要分析一下数据，显示地域相关的用词</p>

<p>可以先对向量pSF与pNY进行排序，然后按照顺序打印出来，将下面的代码添加到文件中：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#最具表征性的词汇显示函数</span>
<span class="k">def</span> <span class="nf">getTopWords</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span><span class="n">sf</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">operator</span>
    <span class="n">vocabList</span><span class="p">,</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="o">=</span><span class="n">localWords</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span><span class="n">sf</span><span class="p">)</span>
    <span class="n">topNY</span><span class="o">=</span><span class="p">[];</span><span class="n">topSF</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p0V</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">p0V</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;-</span><span class="mf">6.0</span><span class="p">:</span><span class="n">topSF</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">vocabList</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">p0V</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">p1V</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;-</span><span class="mf">6.0</span><span class="p">:</span><span class="n">topNY</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">vocabList</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">p1V</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">sortedSF</span><span class="o">=</span><span class="nb">sorted</span><span class="p">(</span><span class="n">topSF</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">"SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**"</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sortedSF</span><span class="p">:</span>
        <span class="k">print</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">sortedNY</span><span class="o">=</span><span class="nb">sorted</span><span class="p">(</span><span class="n">topNY</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">"NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**"</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sortedNY</span><span class="p">:</span>
        <span class="k">print</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<p>函数 getTopWords() 使用两个 RSS 源作为输入，然后训练并测试朴素贝叶斯分类器，返回使用的概率值。然后创建两个列表用于元组的存储，与之前返回排名最高的 X 个单词不同，这里可以返回大于某个阈值的所有词，这些元组会按照它们的条件概率进行排序。</p>

<p>保存 bayes.py 文件，在python提示符下输入：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nb">reload</span><span class="p">(</span><span class="n">bayes</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">module</span> <span class="s">'bayes'</span> <span class="k">from</span> <span class="s">'bayes.pyc'</span><span class="o">&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">bayes</span><span class="o">.</span><span class="n">getTopWords</span><span class="p">(</span><span class="n">ny</span><span class="p">,</span><span class="n">sf</span><span class="p">)</span>
<span class="n">the</span> <span class="n">error</span> <span class="n">rate</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.55</span>
<span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span><span class="n">SF</span><span class="o">**</span>
<span class="n">how</span>
<span class="n">last</span>
<span class="n">man</span>
<span class="o">...</span>
<span class="n">veteran</span>
<span class="n">still</span>
<span class="n">ends</span>
<span class="n">late</span>
<span class="n">off</span>
<span class="n">own</span>
<span class="n">know</span>
<span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span><span class="n">NY</span><span class="o">**</span>
<span class="n">someone</span>
<span class="n">meet</span>
<span class="o">...</span>
<span class="n">apparel</span>
<span class="n">recalled</span>
<span class="n">starting</span>
<span class="n">strings</span>
</code></pre></div></div>

<p>当注释掉用于移除高频词的三行代码，然后比较注释前后的分类性能，去掉这几行代码之后，错误率为54%，，而保留这些代码得到的错误率为70%。这里观察到，这些留言中出现次数最多的前30个词涵盖了所有用词的30%，vocabList的大小约为3000个词，也就是说，词汇表中的一小部分单词却占据了所有文本用词的一大部分。产生这种现象的原因是因为语言中大部分都是冗余和结构辅助性内容。另一个常用的方法是不仅移除高频词，同时从某个预定高频词中移除结构上的辅助词，该词表称为停用词表。</p>

<p>最后输出的单词，可以看出程序输出了大量的停用词，可以移除固定的停用词看看结果如何，这样做的花，分类错误率也会降低。</p>

<p><a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/4.NaiveBayes/bayes.py</a></p>

<hr />

<ul>
  <li><strong>作者：<a href="http://www.apache.wiki/display/~xuxin">羊三</a> <a href="http://www.apache.wiki/display/~chenyao">小瑶</a></strong></li>
  <li><a href="https://github.com/apachecn/MachineLearning">GitHub地址</a>: <a href="https://github.com/apachecn/MachineLearning">https://github.com/apachecn/MachineLearning</a></li>
  <li><strong>版权声明：欢迎转载学习 =&gt; 请标注信息来源于 <a href="http://www.apachecn.org/">ApacheCN</a></strong></li>
</ul>


                <nav class="c-page__nav">
  
    
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/blog2/11ReadBook/04MachineLearningPractice/03%E5%86%B3%E7%AD%96%E6%A0%91">
      〈 <span class="u-margin-right-tiny"></span> 决策树
    </a>
  

  
    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/blog2/11ReadBook/04MachineLearningPractice/05Logistic%E5%9B%9E%E5%BD%92">
      Logistic回归 <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

            </div>
        </div>
    </main>
</div>

</body>
</html>
