<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="en"><!--<![endif]-->
    <head>
<meta charset="utf-8">
<title>14.利用SVD简化数据 &mdash; 魑魅魍魉</title>

<meta name="author" content="niult">






<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">



<link href="../../../theme/css/main.css" media="screen, projection"
      rel="stylesheet" type="text/css">

<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
</head>

<body>

<script src="../../../theme/js/modernizr-2.0.js"></script>
<script src="../../../theme/js/ender.js"></script>
<script src="../../../theme/js/octopress.js" type="text/javascript"></script>
<script src="../../../theme/js/echarts.min.js" type="text/javascript"></script>
<script src="../../../theme/js/require.min.js" type="text/javascript"></script>

<header role="banner"><hgroup>
  <h1><a href="../../../">魑魅魍魉</a></h1>
</hgroup></header>
<nav role="navigation">    <ul class="subscription" data-subscription="rss">
    </ul>


<ul class="main-navigation">
            <li >
                <a href="../../../category/01chang yong gong ju.html">01常用工具</a>
            </li>
            <li >
                <a href="../../../category/02.wo ai du shu.html">02.我爱读书</a>
            </li>
            <li >
                <a href="../../../category/algorithms.html">Algorithms</a>
            </li>
            <li >
                <a href="../../../category/book.html">Book</a>
            </li>
            <li >
                <a href="../../../category/book-pydata.html">Book-pydata</a>
            </li>
            <li >
                <a href="../../../category/deep-learning-with-python.html">Deep-learning-with-python</a>
            </li>
            <li class="active">
                <a href="../../../category/ji qi xue xi shi zhan.html">机器学习实战</a>
            </li>
            <li >
                <a href="../../../category/ke wai du wu.html">课外读物</a>
            </li>
            <li >
                <a href="../../../category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a>
            </li>
            <li >
                <a href="../../../category/shen du xue xi.html">深度学习</a>
            </li>
            <li >
                <a href="../../../category/shen jing wang luo.html">神经网络</a>
            </li>
            <li >
                <a href="../../../category/shu ju wa jue.html">数据挖掘</a>
            </li>
            <li >
                <a href="../../../category/shu xue ji chu.html">数学基础</a>
            </li>
            <li >
                <a href="../../../category/tf-example.html">Tf-example</a>
            </li>
            <li >
                <a href="../../../category/tool1.html">Tool1</a>
            </li>
            <li >
                <a href="../../../category/tool2.html">Tool2</a>
            </li>
            <li >
                <a href="../../../category/tools.html">Tools</a>
            </li>
            <li >
                <a href="../../../category/tui jian xi tong.html">推荐系统</a>
            </li>
            <li >
                <a href="../../../category/wen ben wa jue.html">文本挖掘</a>
            </li>
</ul>
</nav>
<div id="main">
    <div id="content">
    <div>

        <h4>Contents</h4>
        

        <article class="hentry" role="article">
<header>
        <h1 class="entry-title">14.利用SVD简化数据</h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第14章 利用SVD简化数据</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>SVD 概述</h2>
<div class="highlight"><pre><span></span>奇异值分解（SVD, Singular Value Decomposition）:
    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。
</pre></div>
<h2>SVD 场景</h2>
<blockquote>
<p>信息检索-隐性语义检索（Lstent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p>
</blockquote>
<p>隐性语义索引：矩阵 = 文档 + 词语
* 是最早的 SVD 应用之一，我们称利用 SVD 的方法为隐性语义索引（LSI）或隐性语义分析（LSA）。</p>
<p><img alt="LSA举例" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/使用SVD简化数据-LSI举例.png"/></p>
<blockquote>
<p>推荐系统</p>
</blockquote>
<ol>
<li>利用 SVD 从数据中构建一个主题空间。</li>
<li>再在该空间下计算其相似度。(从高维-低维空间的转化，在低维空间来计算相似度，SVD 提升了推荐系统的效率。)</li>
</ol>
<p><img alt="主题空间案例1" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/SVD_推荐系统_主题空间案例1.jpg?raw=true"/></p>
<ul>
<li>上图右边标注的为一组共同特征，表示美式 BBQ 空间；另一组在上图右边未标注的为日式食品 空间。</li>
</ul>
<blockquote>
<p>图像压缩</p>
</blockquote>
<p>例如：<code>32*32=1024 =&gt; 32*2+2*1+32*2=130</code>(2*1表示去掉了除对角线的0), 几乎获得了10倍的压缩比。</p>
<p><img alt="SVD公式" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/使用SVD简化数据-SVD公式.jpg?raw=true"/></p>
<h2>SVD 原理</h2>
<h3>SVD 工作原理</h3>
<blockquote>
<p>矩阵分解</p>
</blockquote>
<ul>
<li>矩阵分解是将数据矩阵分解为多个独立部分的过程。</li>
<li>矩阵分解可以将原始矩阵表示成新的易于处理的形式，这种新形式是两个或多个矩阵的乘积。（类似代数中的因数分解）</li>
<li>举例：如何将12分解成两个数的乘积？（1，12）、（2，6）、（3，4）都是合理的答案。</li>
</ul>
<blockquote>
<p>SVD 是矩阵分解的一种类型，也是矩阵分解最常见的技术</p>
</blockquote>
<ul>
<li>SVD 将原始的数据集矩阵 Data 分解成三个矩阵 U、∑、V</li>
<li>举例：如果原始矩阵 \(Data_{m*n}\) 是m行n列，<ul>
<li>\(U_{m*n}\) 表示m行n列</li>
<li>\(∑_{m*k}\) 表示m行k列</li>
<li>\(V_{k*n}\) 表示k行n列。</li>
</ul>
</li>
</ul>
<p>\(Data_{m*n} = U_{m*k} * ∑<em k_42_n="k*n">{k*k} * V</em>\)</p>
<p><img alt="SVD公式" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/使用SVD简化数据-SVD公式.jpg?raw=true"/></p>
<p>具体的案例：（大家可以试着推导一下：https://wenku.baidu.com/view/b7641217866fb84ae45c8d17.html ）</p>
<p><img alt="SVD公式" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/SVD公式的测试案例.jpg?raw=true"/></p>
<ul>
<li>上述分解中会构建出一个矩阵∑，该矩阵只有对角元素，其他元素均为0(近似于0)。另一个惯例就是，∑的对角元素是从大到小排列的。这些对角元素称为奇异值。</li>
<li>奇异值与特征值(PCA 数据中重要特征)是有关系的。这里的奇异值就是矩阵 \(Data * Data^T\) 特征值的平方根。</li>
<li>普遍的事实：在某个奇异值的数目(r 个=&gt;奇异值的平方和累加到总值的90%以上)之后，其他的奇异值都置为0(近似于0)。这意味着数据集中仅有 r 个重要特征，而其余特征则都是噪声或冗余特征。</li>
</ul>
<h3>SVD 算法特点</h3>
<div class="highlight"><pre><span></span>优点：简化数据，去除噪声，优化算法的结果
缺点：数据的转换可能难以理解
使用的数据类型：数值型数据
</pre></div>
<h2>推荐系统</h2>
<h3>推荐系统 概述</h3>
<p><code>推荐系统是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程。</code></p>
<h3>推荐系统 场景</h3>
<ol>
<li>Amazon 会根据顾客的购买历史向他们推荐物品</li>
<li>Netflix 会向其用户推荐电影</li>
<li>新闻网站会对用户推荐新闻频道</li>
</ol>
<h3>推荐系统 要点</h3>
<blockquote>
<p>基于协同过滤(collaborative filtering) 的推荐引擎</p>
</blockquote>
<ul>
<li>利用Python 实现 SVD(Numpy 有一个称为 linalg 的线性代数工具箱)</li>
<li>协同过滤：是通过将用户和其他用户的数据进行对比来实现推荐的。</li>
<li>当知道了两个用户或两个物品之间的相似度，我们就可以利用已有的数据来预测未知用户的喜好。</li>
</ul>
<blockquote>
<p>基于物品的相似度和基于用户的相似度：物品比较少则选择物品相似度，用户比较少则选择用户相似度。【矩阵还是小一点好计算】</p>
</blockquote>
<ul>
<li>基于物品的相似度：计算物品之间的距离。【耗时会随物品数量的增加而增加】</li>
<li>由于物品A和物品C 相似度(相关度)很高，所以给买A的人推荐C。</li>
</ul>
<p><img alt="SVD公式" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/使用SVD简化数据-基于物品相似度.png"/></p>
<ul>
<li>基于用户的相似度：计算用户之间的距离。【耗时会随用户数量的增加而增加】</li>
<li>由于用户A和用户C 相似度(相关度)很高，所以A和C是兴趣相投的人，对于C买的物品就会推荐给A。</li>
</ul>
<p><img alt="SVD公式" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/使用SVD简化数据-基于用户相似度.png"/></p>
<blockquote>
<p>相似度计算</p>
</blockquote>
<ul>
<li>inA, inB 对应的是 列向量</li>
<li>欧氏距离：指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。二维或三维中的欧氏距离就是两点之间的实际距离。<ul>
<li>相似度= 1/(1+欧式距离)</li>
<li><code>相似度= 1.0/(1.0 + la.norm(inA - inB))</code></li>
<li>物品对越相似，它们的相似度值就越大。</li>
</ul>
</li>
<li>皮尔逊相关系数：度量的是两个向量之间的相似度。<ul>
<li>相似度= 0.5 + 0.5*corrcoef() 【皮尔逊相关系数的取值范围从 -1 到 +1，通过函数0.5 + 0.5*corrcoef()这个函数计算，把值归一化到0到1之间】</li>
<li><code>相似度= 0.5 + 0.5 * corrcoef(inA, inB, rowvar = 0)[0][1]</code></li>
<li>相对欧氏距离的优势：它对用户评级的量级并不敏感。</li>
</ul>
</li>
<li>余弦相似度：计算的是两个向量夹角的余弦值。<ul>
<li>余弦值 = (A·B)/(||A||·||B||) 【余弦值的取值范围也在-1到+1之间】</li>
<li>相似度= 0.5 + 0.5*余弦值</li>
<li><code>相似度= 0.5 + 0.5*( float(inA.T*inB) / la.norm(inA)*la.norm(inB))</code></li>
<li>如果夹角为90度，则相似度为0；如果两个向量的方向相同，则相似度为1.0。</li>
</ul>
</li>
</ul>
<blockquote>
<p>推荐系统的评价</p>
</blockquote>
<ul>
<li>采用交叉测试的方法。【拆分数据为训练集和测试集】</li>
<li>推荐引擎评价的指标： 最小均方根误差(Root mean squared error, RMSE)，也称标准误差(Standard error)，就是计算均方误差的平均值然后取其平方根。<ul>
<li>如果RMSE=1, 表示相差1个星级；如果RMSE=2.5, 表示相差2.5个星级。</li>
</ul>
</li>
</ul>
<h3>推荐系统 原理</h3>
<ul>
<li>推荐系统的工作过程：给定一个用户，系统会为此用户返回N个最好的推荐菜。</li>
<li>实现流程大致如下：<ol>
<li>寻找用户没有评级的菜肴，即在用户-物品矩阵中的0值。</li>
<li>在用户没有评级的所有物品中，对每个物品预计一个可能的评级分数。这就是说：我们认为用户可能会对物品的打分（这就是相似度计算的初衷）。</li>
<li>对这些物品的评分从高到低进行排序，返回前N个物品。</li>
</ol>
</li>
</ul>
<h3>项目案例: 餐馆菜肴推荐系统</h3>
<h4>项目概述</h4>
<p><code>假如一个人在家决定外出吃饭，但是他并不知道该到哪儿去吃饭，该点什么菜。推荐系统可以帮他做到这两点。</code></p>
<h4>开发流程</h4>
<blockquote>
<p>收集 并 准备数据</p>
</blockquote>
<p><img alt="SVD 矩阵" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/项目数据导入.jpg?raw=true"/></p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">loadExData3</span><span class="p">():</span>
    <span class="c1"># 利用SVD提高推荐效果，菜肴矩阵</span>
    <span class="sd">"""</span>
<span class="sd">    行：代表人</span>
<span class="sd">    列：代表菜肴名词</span>
<span class="sd">    值：代表人对菜肴的评分，0表示未评分</span>
<span class="sd">    """</span>
    <span class="k">return</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
</pre></div>
<blockquote>
<p>分析数据: 这里不做过多的讨论(当然此处可以对比不同距离之间的差别)</p>
<p>训练算法: 通过调用 recommend() 函数进行推荐</p>
</blockquote>
<p>recommend() 会调用 基于物品相似度 或者是 基于SVD，得到推荐的物品评分。</p>
<ul>
<li>1.基于物品相似度</li>
</ul>
<p><img alt="基于物品相似度" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/基于物品相似度.jpg?raw=true"/></p>
<p><img alt="欧式距离的计算方式" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/欧式距离的计算方式.jpg?raw=true"/></p>
<div class="highlight"><pre><span></span><span class="c1"># 基于物品相似度的推荐引擎</span>
<span class="k">def</span> <span class="nf">standEst</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">simMeas</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="sd">"""standEst(计算某用户未评分物品中，以对该物品和其他物品评分的用户的物品相似度，然后进行综合评分)</span>

<span class="sd">    Args:</span>
<span class="sd">        dataMat         训练数据集</span>
<span class="sd">        user            用户编号</span>
<span class="sd">        simMeas         相似度计算方法</span>
<span class="sd">        item            未评分的物品编号</span>
<span class="sd">    Returns:</span>
<span class="sd">        ratSimTotal/simTotal     评分（0～5之间的值）</span>
<span class="sd">    """</span>
    <span class="c1"># 得到数据集中的物品数目</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataMat</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># 初始化两个评分值</span>
    <span class="n">simTotal</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">ratSimTotal</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># 遍历行中的每个物品（对用户评过分的物品进行遍历，并将它与其他物品进行比较）</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">userRating</span> <span class="o">=</span> <span class="n">dataMat</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="c1"># 如果某个物品的评分值为0，则跳过这个物品</span>
        <span class="k">if</span> <span class="n">userRating</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="c1"># 寻找两个用户都评级的物品</span>
        <span class="c1"># 变量 overLap 给出的是两个物品当中已经被评分的那个元素的索引ID</span>
        <span class="c1"># logical_and 计算x1和x2元素的真值。</span>
        <span class="n">overLap</span> <span class="o">=</span> <span class="n">nonzero</span><span class="p">(</span><span class="n">logical_and</span><span class="p">(</span><span class="n">dataMat</span><span class="p">[:,</span> <span class="n">item</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dataMat</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># 如果相似度为0，则两着没有任何重合元素，终止本次循环</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">overLap</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># 如果存在重合的物品，则基于这些重合物重新计算相似度。</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="n">simMeas</span><span class="p">(</span><span class="n">dataMat</span><span class="p">[</span><span class="n">overLap</span><span class="p">,</span> <span class="n">item</span><span class="p">],</span> <span class="n">dataMat</span><span class="p">[</span><span class="n">overLap</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
        <span class="c1"># print 'the %d and %d similarity is : %f'(iten,j,similarity)</span>
        <span class="c1"># 相似度会不断累加，每次计算时还考虑相似度和当前用户评分的乘积</span>
        <span class="c1"># similarity  用户相似度，   userRating 用户评分</span>
        <span class="n">simTotal</span> <span class="o">+=</span> <span class="n">similarity</span>
        <span class="n">ratSimTotal</span> <span class="o">+=</span> <span class="n">similarity</span> <span class="o">*</span> <span class="n">userRating</span>
    <span class="k">if</span> <span class="n">simTotal</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="c1"># 通过除以所有的评分总和，对上述相似度评分的乘积进行归一化，使得最后评分在0~5之间，这些评分用来对预测值进行排序</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ratSimTotal</span><span class="o">/</span><span class="n">simTotal</span>
</pre></div>
<ul>
<li>2.基于SVD(参考地址：http://www.codeweblog.com/svd-%E7%AC%94%E8%AE%B0/)</li>
</ul>
<p><img alt="基于SVD.png" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/14.SVD/基于SVD.png"/></p>
<div class="highlight"><pre><span></span><span class="c1"># 基于SVD的评分估计</span>
<span class="c1"># 在recommend() 中，这个函数用于替换对standEst()的调用，该函数对给定用户给定物品构建了一个评分估计值</span>
<span class="k">def</span> <span class="nf">svdEst</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">simMeas</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="sd">"""svdEst(计算某用户未评分物品中，以对该物品和其他物品评分的用户的物品相似度，然后进行综合评分)</span>

<span class="sd">    Args:</span>
<span class="sd">        dataMat         训练数据集</span>
<span class="sd">        user            用户编号</span>
<span class="sd">        simMeas         相似度计算方法</span>
<span class="sd">        item            未评分的物品编号</span>
<span class="sd">    Returns:</span>
<span class="sd">        ratSimTotal/simTotal     评分（0～5之间的值）</span>
<span class="sd">    """</span>
    <span class="c1"># 物品数目</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataMat</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># 对数据集进行SVD分解</span>
    <span class="n">simTotal</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">ratSimTotal</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># 奇异值分解</span>
    <span class="c1"># 在SVD分解之后，我们只利用包含了90%能量值的奇异值，这些奇异值会以NumPy数组的形式得以保存</span>
    <span class="n">U</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">dataMat</span><span class="p">)</span>

    <span class="c1"># # 分析 Sigma 的长度取值</span>
    <span class="c1"># analyse_data(Sigma, 20)</span>

    <span class="c1"># 如果要进行矩阵运算，就必须要用这些奇异值构建出一个对角矩阵</span>
    <span class="n">Sig4</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">[:</span> <span class="mi">4</span><span class="p">])</span>
    <span class="c1"># 利用U矩阵将物品转换到低维空间中，构建转换后的物品(物品+4个主要的特征)</span>
    <span class="n">xformedItems</span> <span class="o">=</span> <span class="n">dataMat</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">Sig4</span><span class="o">.</span><span class="n">I</span>
    <span class="c1"># 对于给定的用户，for循环在用户对应行的元素上进行遍历，</span>
    <span class="c1"># 这和standEst()函数中的for循环的目的一样，只不过这里的相似度计算时在低维空间下进行的。</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">userRating</span> <span class="o">=</span> <span class="n">dataMat</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">userRating</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">j</span> <span class="o">==</span> <span class="n">item</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="c1"># 相似度的计算方法也会作为一个参数传递给该函数</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="n">simMeas</span><span class="p">(</span><span class="n">xformedItems</span><span class="p">[</span><span class="n">item</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xformedItems</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="c1"># for 循环中加入了一条print语句，以便了解相似度计算的进展情况。如果觉得累赘，可以去掉</span>
        <span class="k">print</span> <span class="s1">'the </span><span class="si">%d</span><span class="s1"> and </span><span class="si">%d</span><span class="s1"> similarity is: </span><span class="si">%f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">similarity</span><span class="p">)</span>
        <span class="c1"># 对相似度不断累加求和</span>
        <span class="n">simTotal</span> <span class="o">+=</span> <span class="n">similarity</span>
        <span class="c1"># 对相似度及对应评分值的乘积求和</span>
        <span class="n">ratSimTotal</span> <span class="o">+=</span> <span class="n">similarity</span> <span class="o">*</span> <span class="n">userRating</span>
    <span class="k">if</span> <span class="n">simTotal</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 计算估计评分</span>
        <span class="k">return</span> <span class="n">ratSimTotal</span><span class="o">/</span><span class="n">simTotal</span>
</pre></div>
<p>排序获取最后的推荐结果</p>
<div class="highlight"><pre><span></span><span class="c1"># recommend()函数，就是推荐引擎，它默认调用standEst()函数，产生了最高的N个推荐结果。</span>
<span class="c1"># 如果不指定N的大小，则默认值为3。该函数另外的参数还包括相似度计算方法和估计方法</span>
<span class="k">def</span> <span class="nf">recommend</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">simMeas</span><span class="o">=</span><span class="n">cosSim</span><span class="p">,</span> <span class="n">estMethod</span><span class="o">=</span><span class="n">standEst</span><span class="p">):</span>
    <span class="c1"># 寻找未评级的物品</span>
    <span class="c1"># 对给定的用户建立一个未评分的物品列表</span>
    <span class="n">unratedItems</span> <span class="o">=</span> <span class="n">nonzero</span><span class="p">(</span><span class="n">dataMat</span><span class="p">[</span><span class="n">user</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># 如果不存在未评分物品，那么就退出函数</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unratedItems</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">'you rated everything'</span>
    <span class="c1"># 物品的编号和评分值</span>
    <span class="n">itemScores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># 在未评分物品上进行循环</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">unratedItems</span><span class="p">:</span>
        <span class="n">estimatedScore</span> <span class="o">=</span> <span class="n">estMethod</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">simMeas</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="c1"># 寻找前N个未评级物品，调用standEst()来产生该物品的预测得分，该物品的编号和估计值会放在一个元素列表itemScores中</span>
        <span class="n">itemScores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">item</span><span class="p">,</span> <span class="n">estimatedScore</span><span class="p">))</span>
        <span class="c1"># 按照估计得分，对该列表进行排序并返回。列表逆排序，第一个值就是最大值</span>
    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">itemScores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">jj</span><span class="p">:</span> <span class="n">jj</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span> <span class="n">N</span><span class="p">]</span>
</pre></div>
<blockquote>
<p>测试 和 项目调用，可直接参考我们的代码</p>
</blockquote>
<p><a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/14.SVD/svdRecommend.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/14.SVD/svdRecommend.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/14.SVD/svdRecommend.py</a></p>
<h4>要点补充</h4>
<blockquote>
<p>基于内容(content-based)的推荐</p>
</blockquote>
<ol>
<li>通过各种标签来标记菜肴</li>
<li>将这些属性作为相似度计算所需要的数据</li>
<li>这就是：基于内容的推荐。</li>
</ol>
<blockquote>
<p>构建推荐引擎面临的挑战</p>
</blockquote>
<p>问题
<em> 1）在大规模的数据集上，SVD分解会降低程序的速度
</em> 2）存在其他很多规模扩展性的挑战性问题，比如矩阵的表示方法和计算相似度得分消耗资源。
* 3）如何在缺乏数据时给出好的推荐-称为冷启动【简单说：用户不会喜欢一个无效的物品，而用户不喜欢的物品又无效】</p>
<p>建议
<em> 1）在大型系统中，SVD分解(可以在程序调入时运行一次)每天运行一次或者其频率更低，并且还要离线运行。
</em> 2）在实际中，另一个普遍的做法就是离线计算并保存相似度得分。(物品相似度可能被用户重复的调用)
* 3）冷启动问题，解决方案就是将推荐看成是搜索问题，通过各种标签／属性特征进行<code>基于内容的推荐</code>。</p>
<h3>项目案例: 基于 SVD 的图像压缩</h3>
<blockquote>
<p>收集 并 准备数据</p>
</blockquote>
<p>将文本数据转化为矩阵</p>
<div class="highlight"><pre><span></span><span class="c1"># 加载并转换数据</span>
<span class="k">def</span> <span class="nf">imgLoadData</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">myl</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># 打开文本文件，并从文件以数组方式读入字符</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">newRow</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="n">newRow</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">myl</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newRow</span><span class="p">)</span>
    <span class="c1"># 矩阵调入后，就可以在屏幕上输出该矩阵</span>
    <span class="n">myMat</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">myl</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">myMat</span>
</pre></div>
<blockquote>
<p>分析数据: 分析 Sigma 的长度个数</p>
</blockquote>
<p>通常保留矩阵 80% ～ 90% 的能量，就可以得到重要的特征并去除噪声。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">analyse_data</span><span class="p">(</span><span class="n">Sigma</span><span class="p">,</span> <span class="n">loopNum</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="sd">"""analyse_data(分析 Sigma 的长度取值)</span>

<span class="sd">    Args:</span>
<span class="sd">        Sigma         Sigma的值</span>
<span class="sd">        loopNum       循环次数</span>
<span class="sd">    """</span>
    <span class="c1"># 总方差的集合（总能量值）</span>
    <span class="n">Sig2</span> <span class="o">=</span> <span class="n">Sigma</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">SigmaSum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">Sig2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">loopNum</span><span class="p">):</span>
        <span class="n">SigmaI</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">Sig2</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
        <span class="sd">'''</span>
<span class="sd">        根据自己的业务情况，就行处理，设置对应的 Singma 次数</span>

<span class="sd">        通常保留矩阵 80% ～ 90% 的能量，就可以得到重要的特征并取出噪声。</span>
<span class="sd">        '''</span>
        <span class="k">print</span> <span class="s1">'主成分：</span><span class="si">%s</span><span class="s1">, 方差占比：</span><span class="si">%s%%</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="s1">'2.0f'</span><span class="p">),</span> <span class="n">format</span><span class="p">(</span><span class="n">SigmaI</span><span class="o">/</span><span class="n">SigmaSum</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="s1">'4.2f'</span><span class="p">))</span>
</pre></div>
<blockquote>
<p>使用算法: 对比使用 SVD 前后的数据差异对比，对于存储大家可以试着写写</p>
</blockquote>
<p>例如：<code>32*32=1024 =&gt; 32*2+2*1+32*2=130</code>(2*1表示去掉了除对角线的0), 几乎获得了10倍的压缩比。</p>
<div class="highlight"><pre><span></span><span class="c1"># 打印矩阵</span>
<span class="k">def</span> <span class="nf">printMat</span><span class="p">(</span><span class="n">inMat</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
    <span class="c1"># 由于矩阵保护了浮点数，因此定义浅色和深色，遍历所有矩阵元素，当元素大于阀值时打印1，否则打印0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">float</span><span class="p">(</span><span class="n">inMat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">thresh</span><span class="p">:</span>
                <span class="k">print</span> <span class="mi">1</span><span class="p">,</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="mi">0</span><span class="p">,</span>
        <span class="k">print</span> <span class="s1">''</span>


<span class="c1"># 实现图像压缩，允许基于任意给定的奇异值数目来重构图像</span>
<span class="k">def</span> <span class="nf">imgCompress</span><span class="p">(</span><span class="n">numSV</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
    <span class="sd">"""imgCompress( )</span>

<span class="sd">    Args:</span>
<span class="sd">        numSV       Sigma长度   </span>
<span class="sd">        thresh      判断的阈值</span>
<span class="sd">    """</span>
    <span class="c1"># 构建一个列表</span>
    <span class="n">myMat</span> <span class="o">=</span> <span class="n">imgLoadData</span><span class="p">(</span><span class="s1">'input/14.SVD/0_5.txt'</span><span class="p">)</span>

    <span class="k">print</span> <span class="s2">"****original matrix****"</span>
    <span class="c1"># 对原始图像进行SVD分解并重构图像e</span>
    <span class="n">printMat</span><span class="p">(</span><span class="n">myMat</span><span class="p">,</span> <span class="n">thresh</span><span class="p">)</span>

    <span class="c1"># 通过Sigma 重新构成SigRecom来实现</span>
    <span class="c1"># Sigma是一个对角矩阵，因此需要建立一个全0矩阵，然后将前面的那些奇异值填充到对角线上。</span>
    <span class="n">U</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">myMat</span><span class="p">)</span>
    <span class="c1"># SigRecon = mat(zeros((numSV, numSV)))</span>
    <span class="c1"># for k in range(numSV):</span>
    <span class="c1">#     SigRecon[k, k] = Sigma[k]</span>

    <span class="c1"># 分析插入的 Sigma 长度</span>
    <span class="n">analyse_data</span><span class="p">(</span><span class="n">Sigma</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

    <span class="n">SigRecon</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">eye</span><span class="p">(</span><span class="n">numSV</span><span class="p">)</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">[:</span> <span class="n">numSV</span><span class="p">])</span>
    <span class="n">reconMat</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">numSV</span><span class="p">]</span> <span class="o">*</span> <span class="n">SigRecon</span> <span class="o">*</span> <span class="n">VT</span><span class="p">[:</span><span class="n">numSV</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">print</span> <span class="s2">"****reconstructed matrix using </span><span class="si">%d</span><span class="s2"> singular values *****"</span> <span class="o">%</span> <span class="n">numSV</span>
    <span class="n">printMat</span><span class="p">(</span><span class="n">reconMat</span><span class="p">,</span> <span class="n">thresh</span><span class="p">)</span>
</pre></div>
<p><a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/14.SVD/svdRecommend.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/14.SVD/svdRecommend.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/14.SVD/svdRecommend.py</a></p>
<hr/>
<ul>
<li><strong>作者：<a href="http://cwiki.apachecn.org/display/~jiangzhonglian">片刻</a> <a href="http://cwiki.apachecn.org/display/~lihuisong">1988</a></strong></li>
<li><a href="https://github.com/apachecn/MachineLearning">GitHub地址</a>: <a href="https://github.com/apachecn/MachineLearning">https://github.com/apachecn/MachineLearning</a></li>
<li><strong>版权声明：欢迎转载学习 =&gt; 请标注信息来源于 <a href="http://www.apachecn.org/">ApacheCN</a></strong></li>
</ul></div>


            <footer>
<span class="byline author vcard">
    Posted by
    <span class="fn">
            niult
    </span>
</span><time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time><span class="categories">
        <a href="../../../category/ji qi xue xi shi zhan.html">机器学习实战</a>
</span>


<div class="sharing">
</div>            </footer>
        </article>

    </div>
<aside class="sidebar">
    <section>
        <h1>Recent Posts</h1>
        <ul id="recent_posts">
                <li class="post">
                    <a href="../../../pages/2019/01/21-a-first-look-at-a-neural-network.html">2.1-a-first-look-at-a-neural-network</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/35-classifying-movie-reviews.html">3.5-classifying-movie-reviews</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/36-classifying-newswires.html">3.6-classifying-newswires</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/37-predicting-house-prices.html">3.7-predicting-house-prices</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/44-overfitting-and-underfitting.html">4.4-overfitting-and-underfitting</a>
                </li>
        </ul>
    </section>
        <section>

            <h1>Categories</h1>
            <ul id="recent_posts">
                    <li><a href="../../../category/01chang yong gong ju.html">01常用工具</a></li>
                    <li><a href="../../../category/02.wo ai du shu.html">02.我爱读书</a></li>
                    <li><a href="../../../category/algorithms.html">algorithms</a></li>
                    <li><a href="../../../category/book.html">book</a></li>
                    <li><a href="../../../category/book-pydata.html">book-pydata</a></li>
                    <li><a href="../../../category/deep-learning-with-python.html">deep-learning-with-python</a></li>
                    <li><a href="../../../category/ji qi xue xi shi zhan.html">机器学习实战</a></li>
                    <li><a href="../../../category/ke wai du wu.html">课外读物</a></li>
                    <li><a href="../../../category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a></li>
                    <li><a href="../../../category/shen du xue xi.html">深度学习</a></li>
                    <li><a href="../../../category/shen jing wang luo.html">神经网络</a></li>
                    <li><a href="../../../category/shu ju wa jue.html">数据挖掘</a></li>
                    <li><a href="../../../category/shu xue ji chu.html">数学基础</a></li>
                    <li><a href="../../../category/tf-example.html">tf-example</a></li>
                    <li><a href="../../../category/tool1.html">tool1</a></li>
                    <li><a href="../../../category/tool2.html">tool2</a></li>
                    <li><a href="../../../category/tools.html">tools</a></li>
                    <li><a href="../../../category/tui jian xi tong.html">推荐系统</a></li>
                    <li><a href="../../../category/wen ben wa jue.html">文本挖掘</a></li>
            </ul>
        </section>


    <section>
        <h1>Tags</h1>
            <a href="../../../tag/python.html">python</a>, 
            <a href="../../../tag/numpy.html">numpy</a>, 
            <a href="../../../tag/deep-learning.html">deep-learning</a>, 
            <a href="../../../tag/algorithms.html">algorithms</a>, 
            <a href="../../../tag/wen-ben-wa-jue.html">文本挖掘</a>, 
            <a href="../../../tag/shen-jing-wang-luo.html">神经网络</a>, 
            <a href="../../../tag/shu-xue-ji-chu.html">数学基础</a>, 
            <a href="../../../tag/nlp.html">nlp</a>, 
            <a href="../../../tag/tf-example.html">tf-example</a>, 
            <a href="../../../tag/tui-jian-xi-tong.html">推荐系统</a>, 
            <a href="../../../tag/tf.html">tf</a>, 
            <a href="../../../tag/ji-huo-han-shu.html">激活函数</a>, 
            <a href="../../../tag/mapreduce.html">mapreduce</a>, 
            <a href="../../../tag/spark.html">spark</a>, 
            <a href="../../../tag/handbook.html">handbook</a>, 
            <a href="../../../tag/matplotlib.html">matplotlib</a>, 
            <a href="../../../tag/scikit-learn.html">scikit-learn</a>, 
            <a href="../../../tag/latex.html">latex</a>, 
            <a href="../../../tag/pandas.html">pandas</a>, 
            <a href="../../../tag/jupyter.html">jupyter</a>, 
            <a href="../../../tag/plot.html">plot</a>, 
            <a href="../../../tag/pip.html">pip</a>, 
            <a href="../../../tag/geng-xin-suo-you-mo-kuai.html">更新所有模块</a>, 
            <a href="../../../tag/shen-du-xue-xi.html">深度学习</a>, 
            <a href="../../../tag/xun-huan-shen-jing-wang-luo.html">循环神经网络</a>, 
            <a href="../../../tag/pangrank.html">PangRank</a>, 
            <a href="../../../tag/book.html">book</a>, 
            <a href="../../../tag/pydata.html">pydata</a>, 
            <a href="../../../tag/shell.html">shell</a>, 
            <a href="../../../tag/pyhton.html">pyhton</a>
    </section>



    <section>
        <h1>GitHub Repos</h1>
            <a href="https://github.com/1007530194">@1007530194</a> on GitHub
    </section>

</aside>    </div>
</div>
<footer role="contentinfo"><p>
        活到老，学到老，玩到老
    <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>

    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-132396898-1', 'auto');

    ga('require', 'displayfeatures');
    ga('send', 'pageview');
    </script>
</body>
</html>