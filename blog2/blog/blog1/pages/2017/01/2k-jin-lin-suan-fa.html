<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="en"><!--<![endif]-->
    <head>
<meta charset="utf-8">
<title>2.k-近邻算法 &mdash; 魑魅魍魉</title>

<meta name="author" content="niult">






<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">



<link href="../../../theme/css/main.css" media="screen, projection"
      rel="stylesheet" type="text/css">

<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
</head>

<body>

<script src="../../../theme/js/modernizr-2.0.js"></script>
<script src="../../../theme/js/ender.js"></script>
<script src="../../../theme/js/octopress.js" type="text/javascript"></script>
<script src="../../../theme/js/echarts.min.js" type="text/javascript"></script>
<script src="../../../theme/js/require.min.js" type="text/javascript"></script>

<header role="banner"><hgroup>
  <h1><a href="../../../">魑魅魍魉</a></h1>
</hgroup></header>
<nav role="navigation">    <ul class="subscription" data-subscription="rss">
    </ul>


<ul class="main-navigation">
            <li >
                <a href="../../../category/01chang yong gong ju.html">01常用工具</a>
            </li>
            <li >
                <a href="../../../category/02.wo ai du shu.html">02.我爱读书</a>
            </li>
            <li >
                <a href="../../../category/algorithms.html">Algorithms</a>
            </li>
            <li >
                <a href="../../../category/book.html">Book</a>
            </li>
            <li >
                <a href="../../../category/book-pydata.html">Book-pydata</a>
            </li>
            <li >
                <a href="../../../category/deep-learning-with-python.html">Deep-learning-with-python</a>
            </li>
            <li class="active">
                <a href="../../../category/ji qi xue xi shi zhan.html">机器学习实战</a>
            </li>
            <li >
                <a href="../../../category/ke wai du wu.html">课外读物</a>
            </li>
            <li >
                <a href="../../../category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a>
            </li>
            <li >
                <a href="../../../category/shen du xue xi.html">深度学习</a>
            </li>
            <li >
                <a href="../../../category/shen jing wang luo.html">神经网络</a>
            </li>
            <li >
                <a href="../../../category/shu ju wa jue.html">数据挖掘</a>
            </li>
            <li >
                <a href="../../../category/shu xue ji chu.html">数学基础</a>
            </li>
            <li >
                <a href="../../../category/tf-example.html">Tf-example</a>
            </li>
            <li >
                <a href="../../../category/tool1.html">Tool1</a>
            </li>
            <li >
                <a href="../../../category/tool2.html">Tool2</a>
            </li>
            <li >
                <a href="../../../category/tools.html">Tools</a>
            </li>
            <li >
                <a href="../../../category/tui jian xi tong.html">推荐系统</a>
            </li>
            <li >
                <a href="../../../category/wen ben wa jue.html">文本挖掘</a>
            </li>
</ul>
</nav>
<div id="main">
    <div id="content">
    <div>

        <h4>Contents</h4>
        

        <article class="hentry" role="article">
<header>
        <h1 class="entry-title">2.k-近邻算法</h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第2章 k-近邻算法</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>KNN 概述</h2>
<p><code>k-近邻（kNN, k-NearestNeighbor）算法是一种基本分类与回归方法，我们这里只讨论分类问题中的 k-近邻算法。</code></p>
<p><strong>一句话总结：近朱者赤近墨者黑！</strong> </p>
<p><code>k 近邻算法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k 近邻算法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻算法不具有显式的学习过程。</code></p>
<p><code>k 近邻算法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。 k值的选择、距离度量以及分类决策规则是k近邻算法的三个基本要素。</code></p>
<h2>KNN 场景</h2>
<p>电影可以按照题材分类，那么如何区分 <code>动作片</code> 和 <code>爱情片</code> 呢？<br/>
1. 动作片：打斗次数更多
2. 爱情片：亲吻次数更多</p>
<p>基于电影中的亲吻、打斗出现的次数，使用 k-近邻算法构造程序，就可以自动划分电影的题材类型。</p>
<p><img alt="电影视频案例" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/knn-1-movie.png" title="电影视频案例"/></p>
<div class="highlight"><pre><span></span>现在根据上面我们得到的样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到 k 个距离最近的电影。
假定 k=3，则三个最靠近的电影依次是， He's Not Really into Dudes 、 Beautiful Woman 和 California Man。
knn 算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。
</pre></div>
<h2>KNN 原理</h2>
<blockquote>
<p>KNN 工作原理</p>
</blockquote>
<ol>
<li>假设有一个带有标签的样本数据集（训练样本集），其中包含每条数据与所属分类的对应关系。</li>
<li>输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较。<ol>
<li>计算新数据与样本数据集中每条数据的距离。</li>
<li>对求得的所有距离进行排序（从小到大，越小表示越相似）。</li>
<li>取前 k （k 一般小于等于 20 ）个样本数据对应的分类标签。</li>
</ol>
</li>
<li>求 k 个数据中出现次数最多的分类标签作为新数据的分类。</li>
</ol>
<blockquote>
<p>KNN 通俗理解</p>
</blockquote>
<p>给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的 k 个实例，这 k 个实例的多数属于某个类，就把该输入实例分为这个类。</p>
<blockquote>
<p>KNN 开发流程</p>
</blockquote>
<div class="highlight"><pre><span></span>收集数据：任何方法
准备数据：距离计算所需要的数值，最好是结构化的数据格式
分析数据：任何方法
训练算法：此步骤不适用于 k-近邻算法
测试算法：计算错误率
使用算法：输入样本数据和结构化的输出结果，然后运行 k-近邻算法判断输入数据分类属于哪个分类，最后对计算出的分类执行后续处理
</pre></div>
<blockquote>
<p>KNN 算法特点</p>
</blockquote>
<div class="highlight"><pre><span></span>优点：精度高、对异常值不敏感、无数据输入假定
缺点：计算复杂度高、空间复杂度高
适用数据范围：数值型和标称型
</pre></div>
<h2>KNN 项目案例</h2>
<h3>项目案例1: 优化约会网站的配对效果</h3>
<p><a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/src/python/2.KNN/kNN.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py</a></p>
<h4>项目概述</h4>
<p>海伦使用约会网站寻找约会对象。经过一段时间之后，她发现曾交往过三种类型的人:
<em> 不喜欢的人
</em> 魅力一般的人
* 极具魅力的人</p>
<p>她希望：
1. 工作日与魅力一般的人约会
2. 周末与极具魅力的人约会
3. 不喜欢的人则直接排除掉</p>
<p>现在她收集到了一些约会网站未曾记录的数据信息，这更有助于匹配对象的归类。</p>
<h4>开发流程</h4>
<div class="highlight"><pre><span></span>收集数据：提供文本文件
准备数据：使用 Python 解析文本文件
分析数据：使用 Matplotlib 画二维散点图
训练算法：此步骤不适用于 k-近邻算法
测试算法：使用海伦提供的部分数据作为测试样本。
        测试样本和非测试样本的区别在于：
            测试样本是已经完成分类的数据，如果预测分类与实际类别不同，则标记为一个错误。
使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型。
</pre></div>
<blockquote>
<p>收集数据：提供文本文件</p>
</blockquote>
<p>海伦把这些约会对象的数据存放在文本文件 <a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/input/2.KNN/datingTestSet2.txt">datingTestSet2.txt</a> 中，总共有 1000 行。海伦约会的对象主要包含以下 3 种特征：</p>
<ul>
<li>每年获得的飞行常客里程数</li>
<li>玩视频游戏所耗时间百分比</li>
<li>每周消费的冰淇淋公升数</li>
</ul>
<p>文本文件数据格式如下：</p>
<div class="highlight"><pre><span></span>40920   8.326976    0.953952    3
14488   7.153469    1.673904    2
26052   1.441871    0.805124    1
75136   13.147394   0.428964    1
38344   1.669788    0.134296    1
</pre></div>
<blockquote>
<p>准备数据：使用 Python 解析文本文件</p>
</blockquote>
<p>将文本记录转换为 NumPy 的解析程序</p>
<p>```python
def file2matrix(filename):
    """
    Desc:
        导入训练数据
    parameters:
        filename: 数据文件路径
    return: 
        数据矩阵 returnMat 和对应的类别 classLabelVector
    """
    fr = open(filename)
    # 获得文件中的数据行的行数
    numberOfLines = len(fr.readlines())
    # 生成对应的空矩阵
    # 例如：zeros(2，3)就是生成一个 2*3的矩阵，各个位置上全是 0 
    returnMat = zeros((numberOfLines, 3))  # prepare matrix to return
    classLabelVector = []  # prepare labels return
    fr = open(filename)
    index = 0
    for line in fr.readlines():
        # str.strip([chars]) --返回移除字符串头尾指定的字符生成的新字符串
        line = line.strip()
        # 以 '\t' 切割字符串
        listFromLine = line.split('\t')
        # 每列的属性数据
        returnMat[index, :] = listFromLine[0:3]
        # 每列的类别数据，就是 label 标签数据
        classLabelVector.append(int(listFromLine[-1]))
        index += 1
    # 返回数据矩阵returnMat和对应的类别classLabelVector
    return returnMat, classLabelVector</p>
<div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="err">分析数据：使用</span> <span class="n">Matplotlib</span> <span class="err">画二维散点图</span>

<span class="sb">``</span><span class="err">`</span><span class="n">python</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">datingDataMat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">datingDataMat</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="mf">15.0</span><span class="o">*</span><span class="n">array</span><span class="p">(</span><span class="n">datingLabels</span><span class="p">),</span> <span class="mf">15.0</span><span class="o">*</span><span class="n">array</span><span class="p">(</span><span class="n">datingLabels</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<p>下图中采用矩阵的第一和第二列属性得到很好的展示效果，清晰地标识了三个不同的样本分类区域，具有不同爱好的人其类别区域也不同。</p>
<p><img alt="Matplotlib 散点图" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/knn_matplotlib_2.png"/></p>
<ul>
<li>归一化数据 （归一化是一个让权重变为统一的过程，更多细节请参考： https://www.zhihu.com/question/19951858 ）</li>
</ul>
<table>
<thead>
<tr>
<th>序号</th>
<th align="center">玩视频游戏所耗时间百分比</th>
<th align="right">每年获得的飞行常客里程数</th>
<th align="right">每周消费的冰淇淋公升数</th>
<th align="right">样本分类</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td align="center">0.8</td>
<td align="right">400</td>
<td align="right">0.5</td>
<td align="right">1</td>
</tr>
<tr>
<td>2</td>
<td align="center">12</td>
<td align="right">134 000</td>
<td align="right">0.9</td>
<td align="right">3</td>
</tr>
<tr>
<td>3</td>
<td align="center">0</td>
<td align="right">20 000</td>
<td align="right">1.1</td>
<td align="right">2</td>
</tr>
<tr>
<td>4</td>
<td align="center">67</td>
<td align="right">32 000</td>
<td align="right">0.1</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>样本3和样本4的距离：
$$\sqrt{(0-67)^2 + (20000-32000)^2 + (1.1-0.1)^2 }$$</p>
<p>归一化特征值，消除特征之间量级不同导致的影响</p>
<p><strong>归一化定义：</strong> 我是这样认为的，归一化就是要把你需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内。首先归一化是为了后面数据处理的方便，其次是保正程序运行时收敛加快。 方法有如下：</p>
<p>1) 线性函数转换，表达式如下：　　</p>
<div class="highlight"><pre><span></span>y=(x-MinValue)/(MaxValue-MinValue)

说明：x、y分别为转换前、后的值，MaxValue、MinValue分别为样本的最大值和最小值。
</pre></div>
<p>2) 对数函数转换，表达式如下：　　</p>
<div class="highlight"><pre><span></span>y=log10(x)

说明：以10为底的对数函数转换。

如图：

![对数函数图像](https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/knn_1.png)
</pre></div>
<p>3) 反余切函数转换，表达式如下：</p>
<div class="highlight"><pre><span></span>y=arctan(x)*2/PI

如图：

![反余切函数图像](https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/arctan_arccot.gif)
</pre></div>
<p>4) 式(1)将输入值换算为[-1,1]区间的值，在输出层用式(2)换算回初始值，其中和分别表示训练样本集中负荷的最大值和最小值。　</p>
<p>在统计学中，归一化的具体作用是归纳统一样本的统计分布性。归一化在0-1之间是统计的概率分布，归一化在-1--+1之间是统计的坐标分布。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">autoNorm</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Desc:</span>
<span class="sd">        归一化特征值，消除特征之间量级不同导致的影响</span>
<span class="sd">    parameter:</span>
<span class="sd">        dataSet: 数据集</span>
<span class="sd">    return:</span>
<span class="sd">        归一化后的数据集 normDataSet. ranges和minVals即最小值与范围，并没有用到</span>

<span class="sd">    归一化公式：</span>
<span class="sd">        Y = (X-Xmin)/(Xmax-Xmin)</span>
<span class="sd">        其中的 min 和 max 分别是数据集中的最小特征值和最大特征值。该函数可以自动将数字特征值转化为0到1的区间。</span>
<span class="sd">    """</span>
    <span class="c1"># 计算每种属性的最大值、最小值、范围</span>
    <span class="n">minVals</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">maxVals</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># 极差</span>
    <span class="n">ranges</span> <span class="o">=</span> <span class="n">maxVals</span> <span class="o">-</span> <span class="n">minVals</span>
    <span class="n">normDataSet</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># 生成与最小值之差组成的矩阵</span>
    <span class="n">normDataSet</span> <span class="o">=</span> <span class="n">dataSet</span> <span class="o">-</span> <span class="n">tile</span><span class="p">(</span><span class="n">minVals</span><span class="p">,</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># 将最小值之差除以范围组成矩阵</span>
    <span class="n">normDataSet</span> <span class="o">=</span> <span class="n">normDataSet</span> <span class="o">/</span> <span class="n">tile</span><span class="p">(</span><span class="n">ranges</span><span class="p">,</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># element wise divide</span>
    <span class="k">return</span> <span class="n">normDataSet</span><span class="p">,</span> <span class="n">ranges</span><span class="p">,</span> <span class="n">minVals</span>
</pre></div>
<blockquote>
<p>训练算法：此步骤不适用于 k-近邻算法</p>
</blockquote>
<p>因为测试数据每一次都要与全量的训练数据进行比较，所以这个过程是没有必要的。</p>
<p>kNN 算法伪代码：</p>
<div class="highlight"><pre><span></span>对于每一个在数据集中的数据点：
    计算目标的数据点（需要分类的数据点）与该数据点的距离
    将距离排序：从小到大
    选取前K个最短距离
    选取这K个中最多的分类类别
    返回该类别来作为目标数据点的预测值
</pre></div>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">classify0</span><span class="p">(</span><span class="n">inX</span><span class="p">,</span> <span class="n">dataSet</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">dataSetSize</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">#距离度量 度量公式为欧氏距离</span>
    <span class="n">diffMat</span> <span class="o">=</span> <span class="n">tile</span><span class="p">(</span><span class="n">inX</span><span class="p">,</span> <span class="p">(</span><span class="n">dataSetSize</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="err">–</span> <span class="n">dataSet</span>
    <span class="n">sqDiffMat</span> <span class="o">=</span> <span class="n">diffMat</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">sqDistances</span> <span class="o">=</span> <span class="n">sqDiffMat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">sqDistances</span><span class="o">**</span><span class="mf">0.5</span>
    
    <span class="c1">#将距离排序：从小到大</span>
    <span class="n">sortedDistIndicies</span> <span class="o">=</span> <span class="n">distances</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>
    <span class="c1">#选取前K个最短距离， 选取这K个中最多的分类类别</span>
    <span class="n">classCount</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="err">：</span>
        <span class="n">voteIlabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">sortedDistIndicies</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">classCount</span><span class="p">[</span><span class="n">voteIlabel</span><span class="p">]</span> <span class="o">=</span> <span class="n">classCount</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">voteIlabel</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> 
    <span class="n">sortedClassCount</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">classCount</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sortedClassCount</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
<blockquote>
<p>测试算法：使用海伦提供的部分数据作为测试样本。如果预测分类与实际类别不同，则标记为一个错误。</p>
</blockquote>
<p>kNN 分类器针对约会网站的测试代码</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">datingClassTest</span><span class="p">():</span>
    <span class="sd">"""</span>
<span class="sd">    Desc:</span>
<span class="sd">        对约会网站的测试方法</span>
<span class="sd">    parameters:</span>
<span class="sd">        none</span>
<span class="sd">    return:</span>
<span class="sd">        错误数</span>
<span class="sd">    """</span>
    <span class="c1"># 设置测试数据的的一个比例（训练数据集比例=1-hoRatio）</span>
    <span class="n">hoRatio</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># 测试范围,一部分测试一部分作为样本</span>
    <span class="c1"># 从文件中加载数据</span>
    <span class="n">datingDataMat</span><span class="p">,</span> <span class="n">datingLabels</span> <span class="o">=</span> <span class="n">file2matrix</span><span class="p">(</span><span class="s1">'input/2.KNN/datingTestSet2.txt'</span><span class="p">)</span>  <span class="c1"># load data setfrom file</span>
    <span class="c1"># 归一化数据</span>
    <span class="n">normMat</span><span class="p">,</span> <span class="n">ranges</span><span class="p">,</span> <span class="n">minVals</span> <span class="o">=</span> <span class="n">autoNorm</span><span class="p">(</span><span class="n">datingDataMat</span><span class="p">)</span>
    <span class="c1"># m 表示数据的行数，即矩阵的第一维</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">normMat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># 设置测试的样本数量， numTestVecs:m表示训练样本的数量</span>
    <span class="n">numTestVecs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">hoRatio</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">'numTestVecs='</span><span class="p">,</span> <span class="n">numTestVecs</span>
    <span class="n">errorCount</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTestVecs</span><span class="p">):</span>
        <span class="c1"># 对数据测试</span>
        <span class="n">classifierResult</span> <span class="o">=</span> <span class="n">classify0</span><span class="p">(</span><span class="n">normMat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">normMat</span><span class="p">[</span><span class="n">numTestVecs</span><span class="p">:</span><span class="n">m</span><span class="p">,</span> <span class="p">:],</span> <span class="n">datingLabels</span><span class="p">[</span><span class="n">numTestVecs</span><span class="p">:</span><span class="n">m</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">"the classifier came back with: </span><span class="si">%d</span><span class="s2">, the real answer is: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">classifierResult</span><span class="p">,</span> <span class="n">datingLabels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">classifierResult</span> <span class="o">!=</span> <span class="n">datingLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span> <span class="n">errorCount</span> <span class="o">+=</span> <span class="mf">1.0</span>
    <span class="k">print</span> <span class="s2">"the total error rate is: </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">errorCount</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">numTestVecs</span><span class="p">))</span>
    <span class="k">print</span> <span class="n">errorCount</span>
</pre></div>
<blockquote>
<p>使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型。</p>
</blockquote>
<p>约会网站预测函数</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">classifyPerson</span><span class="p">():</span>
    <span class="n">resultList</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'not at all'</span><span class="p">,</span> <span class="s1">'in small doses'</span><span class="p">,</span> <span class="s1">'in large doses'</span><span class="p">]</span>
    <span class="n">percentTats</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">raw_input</span><span class="p">(</span><span class="s2">"percentage of time spent playing video games ?"</span><span class="p">))</span>
    <span class="n">ffMiles</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">raw_input</span><span class="p">(</span><span class="s2">"frequent filer miles earned per year?"</span><span class="p">))</span>
    <span class="n">iceCream</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">raw_input</span><span class="p">(</span><span class="s2">"liters of ice cream consumed per year?"</span><span class="p">))</span>
    <span class="n">datingDataMat</span><span class="p">,</span> <span class="n">datingLabels</span> <span class="o">=</span> <span class="n">file2matrix</span><span class="p">(</span><span class="s1">'datingTestSet2.txt'</span><span class="p">)</span>
    <span class="n">normMat</span><span class="p">,</span> <span class="n">ranges</span><span class="p">,</span> <span class="n">minVals</span> <span class="o">=</span> <span class="n">autoNorm</span><span class="p">(</span><span class="n">datingDataMat</span><span class="p">)</span>
    <span class="n">inArr</span> <span class="o">=</span> <span class="n">array</span><span class="p">([</span><span class="n">ffMiles</span><span class="p">,</span> <span class="n">percentTats</span><span class="p">,</span> <span class="n">iceCream</span><span class="p">])</span>
    <span class="n">classifierResult</span> <span class="o">=</span> <span class="n">classify0</span><span class="p">((</span><span class="n">inArr</span><span class="o">-</span><span class="n">minVals</span><span class="p">)</span><span class="o">/</span><span class="n">ranges</span><span class="p">,</span><span class="n">normMat</span><span class="p">,</span><span class="n">datingLabels</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">print</span> <span class="s2">"You will probably like this person: "</span><span class="p">,</span> <span class="n">resultList</span><span class="p">[</span><span class="n">classifierResult</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
<p>实际运行效果如下: </p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">classifyPerson</span><span class="p">()</span>
<span class="n">percentage</span> <span class="n">of</span> <span class="n">time</span> <span class="n">spent</span> <span class="n">playing</span> <span class="n">video</span> <span class="n">games</span><span class="err">?</span><span class="mi">10</span>
<span class="n">frequent</span> <span class="n">flier</span> <span class="n">miles</span> <span class="n">earned</span> <span class="n">per</span> <span class="n">year</span><span class="err">?</span><span class="mi">10000</span>
<span class="n">liters</span> <span class="n">of</span> <span class="n">ice</span> <span class="n">cream</span> <span class="n">consumed</span> <span class="n">per</span> <span class="n">year</span><span class="err">?</span><span class="mf">0.5</span>
<span class="n">You</span> <span class="n">will</span> <span class="n">probably</span> <span class="n">like</span> <span class="n">this</span> <span class="n">person</span><span class="p">:</span> <span class="ow">in</span> <span class="n">small</span> <span class="n">doses</span>
</pre></div>
<h3>项目案例2: 手写数字识别系统</h3>
<p><a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/src/python/2.KNN/kNN.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py</a></p>
<h4>项目概述</h4>
<p>构造一个能识别数字 0 到 9 的基于 KNN 分类器的手写数字识别系统。</p>
<p>需要识别的数字是存储在文本文件中的具有相同的色彩和大小：宽高是 32 像素 * 32 像素的黑白图像。</p>
<h4>开发流程</h4>
<div class="highlight"><pre><span></span>收集数据：提供文本文件。
准备数据：编写函数 img2vector(), 将图像格式转换为分类器使用的向量格式
分析数据：在 Python 命令提示符中检查数据，确保它符合要求
训练算法：此步骤不适用于 KNN
测试算法：编写函数使用提供的部分数据集作为测试样本，测试样本与非测试样本的
         区别在于测试样本是已经完成分类的数据，如果预测分类与实际类别不同，
         则标记为一个错误
使用算法：本例没有完成此步骤，若你感兴趣可以构建完整的应用程序，从图像中提取
         数字，并完成数字识别，美国的邮件分拣系统就是一个实际运行的类似系统
</pre></div>
<blockquote>
<p>收集数据: 提供文本文件</p>
</blockquote>
<p>目录 <a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/input/2.KNN/trainingDigits">trainingDigits</a> 中包含了大约 2000 个例子，每个例子内容如下图所示，每个数字大约有 200 个样本；目录 <a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/input/2.KNN/testDigits">testDigits</a> 中包含了大约 900 个测试数据。</p>
<p><img alt="手写数字数据集的例子" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/knn_2_handWriting.png"/></p>
<blockquote>
<p>准备数据: 编写函数 img2vector(), 将图像文本数据转换为分类器使用的向量</p>
</blockquote>
<p>将图像文本数据转换为向量</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">img2vector</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">returnVect</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1024</span><span class="p">))</span>
    <span class="n">fr</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
        <span class="n">lineStr</span> <span class="o">=</span> <span class="n">fr</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="n">returnVect</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lineStr</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">returnVect</span>
</pre></div>
<blockquote>
<p>分析数据：在 Python 命令提示符中检查数据，确保它符合要求</p>
</blockquote>
<p>在 Python 命令行中输入下列命令测试 img2vector 函数，然后与文本编辑器打开的文件进行比较: </p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">testVector</span> <span class="o">=</span> <span class="n">kNN</span><span class="o">.</span><span class="n">img2vector</span><span class="p">(</span><span class="s1">'testDigits/0_13.txt'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">testVector</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">testVector</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="p">:</span><span class="mi">64</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>
<blockquote>
<p>训练算法：此步骤不适用于 KNN</p>
</blockquote>
<p>因为测试数据每一次都要与全量的训练数据进行比较，所以这个过程是没有必要的。</p>
<blockquote>
<p>测试算法：编写函数使用提供的部分数据集作为测试样本，如果预测分类与实际类别不同，则标记为一个错误</p>
</blockquote>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">handwritingClassTest</span><span class="p">():</span>
    <span class="c1"># 1. 导入训练数据</span>
    <span class="n">hwLabels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">trainingFileList</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="s1">'input/2.KNN/trainingDigits'</span><span class="p">)</span>  <span class="c1"># load the training set</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainingFileList</span><span class="p">)</span>
    <span class="n">trainingMat</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1024</span><span class="p">))</span>
    <span class="c1"># hwLabels存储0～9对应的index位置， trainingMat存放的每个位置对应的图片向量</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">fileNameStr</span> <span class="o">=</span> <span class="n">trainingFileList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">fileStr</span> <span class="o">=</span> <span class="n">fileNameStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># take off .txt</span>
        <span class="n">classNumStr</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fileStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'_'</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">hwLabels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classNumStr</span><span class="p">)</span>
        <span class="c1"># 将 32*32的矩阵-&gt;1*1024的矩阵</span>
        <span class="n">trainingMat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">img2vector</span><span class="p">(</span><span class="s1">'input/2.KNN/trainingDigits/</span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span> <span class="n">fileNameStr</span><span class="p">)</span>

    <span class="c1"># 2. 导入测试数据</span>
    <span class="n">testFileList</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="s1">'input/2.KNN/testDigits'</span><span class="p">)</span>  <span class="c1"># iterate through the test set</span>
    <span class="n">errorCount</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">mTest</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">testFileList</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mTest</span><span class="p">):</span>
        <span class="n">fileNameStr</span> <span class="o">=</span> <span class="n">testFileList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">fileStr</span> <span class="o">=</span> <span class="n">fileNameStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># take off .txt</span>
        <span class="n">classNumStr</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fileStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'_'</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">vectorUnderTest</span> <span class="o">=</span> <span class="n">img2vector</span><span class="p">(</span><span class="s1">'input/2.KNN/testDigits/</span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span> <span class="n">fileNameStr</span><span class="p">)</span>
        <span class="n">classifierResult</span> <span class="o">=</span> <span class="n">classify0</span><span class="p">(</span><span class="n">vectorUnderTest</span><span class="p">,</span> <span class="n">trainingMat</span><span class="p">,</span> <span class="n">hwLabels</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">"the classifier came back with: </span><span class="si">%d</span><span class="s2">, the real answer is: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">classifierResult</span><span class="p">,</span> <span class="n">classNumStr</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">classifierResult</span> <span class="o">!=</span> <span class="n">classNumStr</span><span class="p">):</span> <span class="n">errorCount</span> <span class="o">+=</span> <span class="mf">1.0</span>
    <span class="k">print</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">the total number of errors is: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">errorCount</span>
    <span class="k">print</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">the total error rate is: </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">errorCount</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">mTest</span><span class="p">))</span>
</pre></div>
<blockquote>
<p>使用算法：本例没有完成此步骤，若你感兴趣可以构建完整的应用程序，从图像中提取数字，并完成数字识别，美国的邮件分拣系统就是一个实际运行的类似系统</p>
</blockquote>
<h2>KNN 小结</h2>
<p>经过上面的介绍我们可以知道， k 近邻算法有 三个基本的要素：</p>
<ul>
<li>
<p>k 值的选择</p>
<ul>
<li>k 值的选择会对 k 近邻算法的结果产生重大的影响。</li>
<li>如果选择较小的 k 值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差（approximation error）会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是“学习”的估计误差（estimation error）会增大，预测结果会对近邻的实例点非常敏感。如果邻近的实例点恰巧是噪声，预测就会出错。换句话说，k 值的减小就意味着整体模型变得复杂，容易发生过拟合。</li>
<li>如果选择较大的 k 值，就相当于用较大的邻域中的训练实例进行预测。其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误。 k 值的增大就意味着整体的模型变得简单。</li>
<li>近似误差和估计误差，请看这里：https://www.zhihu.com/question/60793482</li>
</ul>
</li>
<li>
<p>距离度量</p>
<ul>
<li>特征空间中两个实例点的距离是两个实例点相似程度的反映。</li>
<li>k 近邻模型的特征空间一般是 n 维实数向量空间 <img alt="向量空间" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/knn_3.png"/> 。使用的距离是欧氏距离，但也可以是其他距离，如更一般的 <img alt="Lp距离" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/2.KNN/knn_4.png"/> 距离，或者 Minkowski 距离。</li>
</ul>
</li>
<li>
<p>分类决策规则</p>
<ul>
<li>k 近邻算法中的分类决策规则往往是多数表决，即由输入实例的 k 个邻近的训练实例中的多数类决定输入实例的类。</li>
</ul>
</li>
</ul>
<hr/>
<ul>
<li><strong>作者：<a href="http://www.apache.wiki/display/~xuxin">羊三</a> <a href="http://www.apache.wiki/display/~chenyao">小瑶</a></strong></li>
<li><a href="https://github.com/apachecn/MachineLearning">GitHub地址</a>: <a href="https://github.com/apachecn/MachineLearning">https://github.com/apachecn/MachineLearning</a></li>
<li><strong>版权声明：欢迎转载学习 =&gt; 请标注信息来源于 <a href="http://www.apachecn.org/">ApacheCN</a></strong></li>
</ul></div>


            <footer>
<span class="byline author vcard">
    Posted by
    <span class="fn">
            niult
    </span>
</span><time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time><span class="categories">
        <a href="../../../category/ji qi xue xi shi zhan.html">机器学习实战</a>
</span>


<div class="sharing">
</div>            </footer>
        </article>

    </div>
<aside class="sidebar">
    <section>
        <h1>Recent Posts</h1>
        <ul id="recent_posts">
                <li class="post">
                    <a href="../../../pages/2019/01/21-a-first-look-at-a-neural-network.html">2.1-a-first-look-at-a-neural-network</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/35-classifying-movie-reviews.html">3.5-classifying-movie-reviews</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/36-classifying-newswires.html">3.6-classifying-newswires</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/37-predicting-house-prices.html">3.7-predicting-house-prices</a>
                </li>
                <li class="post">
                    <a href="../../../pages/2019/01/44-overfitting-and-underfitting.html">4.4-overfitting-and-underfitting</a>
                </li>
        </ul>
    </section>
        <section>

            <h1>Categories</h1>
            <ul id="recent_posts">
                    <li><a href="../../../category/01chang yong gong ju.html">01常用工具</a></li>
                    <li><a href="../../../category/02.wo ai du shu.html">02.我爱读书</a></li>
                    <li><a href="../../../category/algorithms.html">algorithms</a></li>
                    <li><a href="../../../category/book.html">book</a></li>
                    <li><a href="../../../category/book-pydata.html">book-pydata</a></li>
                    <li><a href="../../../category/deep-learning-with-python.html">deep-learning-with-python</a></li>
                    <li><a href="../../../category/ji qi xue xi shi zhan.html">机器学习实战</a></li>
                    <li><a href="../../../category/ke wai du wu.html">课外读物</a></li>
                    <li><a href="../../../category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a></li>
                    <li><a href="../../../category/shen du xue xi.html">深度学习</a></li>
                    <li><a href="../../../category/shen jing wang luo.html">神经网络</a></li>
                    <li><a href="../../../category/shu ju wa jue.html">数据挖掘</a></li>
                    <li><a href="../../../category/shu xue ji chu.html">数学基础</a></li>
                    <li><a href="../../../category/tf-example.html">tf-example</a></li>
                    <li><a href="../../../category/tool1.html">tool1</a></li>
                    <li><a href="../../../category/tool2.html">tool2</a></li>
                    <li><a href="../../../category/tools.html">tools</a></li>
                    <li><a href="../../../category/tui jian xi tong.html">推荐系统</a></li>
                    <li><a href="../../../category/wen ben wa jue.html">文本挖掘</a></li>
            </ul>
        </section>


    <section>
        <h1>Tags</h1>
            <a href="../../../tag/python.html">python</a>, 
            <a href="../../../tag/numpy.html">numpy</a>, 
            <a href="../../../tag/deep-learning.html">deep-learning</a>, 
            <a href="../../../tag/algorithms.html">algorithms</a>, 
            <a href="../../../tag/wen-ben-wa-jue.html">文本挖掘</a>, 
            <a href="../../../tag/shen-jing-wang-luo.html">神经网络</a>, 
            <a href="../../../tag/shu-xue-ji-chu.html">数学基础</a>, 
            <a href="../../../tag/nlp.html">nlp</a>, 
            <a href="../../../tag/tf-example.html">tf-example</a>, 
            <a href="../../../tag/tui-jian-xi-tong.html">推荐系统</a>, 
            <a href="../../../tag/tf.html">tf</a>, 
            <a href="../../../tag/ji-huo-han-shu.html">激活函数</a>, 
            <a href="../../../tag/mapreduce.html">mapreduce</a>, 
            <a href="../../../tag/spark.html">spark</a>, 
            <a href="../../../tag/handbook.html">handbook</a>, 
            <a href="../../../tag/matplotlib.html">matplotlib</a>, 
            <a href="../../../tag/scikit-learn.html">scikit-learn</a>, 
            <a href="../../../tag/latex.html">latex</a>, 
            <a href="../../../tag/pandas.html">pandas</a>, 
            <a href="../../../tag/jupyter.html">jupyter</a>, 
            <a href="../../../tag/plot.html">plot</a>, 
            <a href="../../../tag/pip.html">pip</a>, 
            <a href="../../../tag/geng-xin-suo-you-mo-kuai.html">更新所有模块</a>, 
            <a href="../../../tag/shen-du-xue-xi.html">深度学习</a>, 
            <a href="../../../tag/xun-huan-shen-jing-wang-luo.html">循环神经网络</a>, 
            <a href="../../../tag/pangrank.html">PangRank</a>, 
            <a href="../../../tag/book.html">book</a>, 
            <a href="../../../tag/pydata.html">pydata</a>, 
            <a href="../../../tag/shell.html">shell</a>, 
            <a href="../../../tag/pyhton.html">pyhton</a>
    </section>



    <section>
        <h1>GitHub Repos</h1>
            <a href="https://github.com/1007530194">@1007530194</a> on GitHub
    </section>

</aside>    </div>
</div>
<footer role="contentinfo"><p>
        活到老，学到老，玩到老
    <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>

    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-132396898-1', 'auto');

    ga('require', 'displayfeatures');
    ga('send', 'pageview');
    </script>
</body>
</html>