<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="en"><!--<![endif]-->
    <head>
<meta charset="utf-8">
<title>魑魅魍魉</title>

<meta name="author" content="niult">




<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">



<link href="./theme/css/main.css" media="screen, projection"
      rel="stylesheet" type="text/css">

<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
</head>

<body>

<script src="./theme/js/modernizr-2.0.js"></script>
<script src="./theme/js/ender.js"></script>
<script src="./theme/js/octopress.js" type="text/javascript"></script>
<script src="./theme/js/echarts.min.js" type="text/javascript"></script>
<script src="./theme/js/require.min.js" type="text/javascript"></script>

<header role="banner"><hgroup>
  <h1><a href="./">魑魅魍魉</a></h1>
</hgroup></header>
<nav role="navigation">    <ul class="subscription" data-subscription="rss">
    </ul>


<ul class="main-navigation">
            <li >
                <a href="./category/01chang yong gong ju.html">01常用工具</a>
            </li>
            <li >
                <a href="./category/02.wo ai du shu.html">02.我爱读书</a>
            </li>
            <li >
                <a href="./category/algorithms.html">Algorithms</a>
            </li>
            <li >
                <a href="./category/book.html">Book</a>
            </li>
            <li >
                <a href="./category/book-pydata.html">Book-pydata</a>
            </li>
            <li >
                <a href="./category/deep-learning-with-python.html">Deep-learning-with-python</a>
            </li>
            <li >
                <a href="./category/ji qi xue xi shi zhan.html">机器学习实战</a>
            </li>
            <li >
                <a href="./category/ke wai du wu.html">课外读物</a>
            </li>
            <li >
                <a href="./category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a>
            </li>
            <li >
                <a href="./category/shen du xue xi.html">深度学习</a>
            </li>
            <li >
                <a href="./category/shen jing wang luo.html">神经网络</a>
            </li>
            <li >
                <a href="./category/shu ju wa jue.html">数据挖掘</a>
            </li>
            <li >
                <a href="./category/shu xue ji chu.html">数学基础</a>
            </li>
            <li >
                <a href="./category/tf-example.html">Tf-example</a>
            </li>
            <li >
                <a href="./category/tool1.html">Tool1</a>
            </li>
            <li >
                <a href="./category/tool2.html">Tool2</a>
            </li>
            <li >
                <a href="./category/tools.html">Tools</a>
            </li>
            <li >
                <a href="./category/tui jian xi tong.html">推荐系统</a>
            </li>
            <li >
                <a href="./category/wen ben wa jue.html">文本挖掘</a>
            </li>
</ul>
</nav>
<div id="main">
    <div id="content">
    <div class="blog-index">
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-08-ti-sheng-fang-fa.html">统计学习方法08-提升方法</a>
        </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

    <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第8章-提升方法">&#31532;8&#31456; &#25552;&#21319;&#26041;&#27861;<a class="anchor-link" href="#第8章-提升方法">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Boost">Boost<a class="anchor-link" href="#Boost">&#182;</a></h1><p>“装袋”（bagging）和“提升”（boost）是构建组合模型的两种最主要的方法，所谓的组合模型是由多个基本模型构成的模型，组合模型的预测效果往往比任意一个基本模型的效果都要好。</p>
<ul>
<li><p>装袋：每个基本模型由从总体样本中随机抽样得到的不同数据集进行训练得到，通过重抽样得到不同训练数据集的过程称为装袋。</p>
</li>
<li><p>提升：每个基本模型训练时的数据集采用不同权重，针对上一个基本模型分类错误的样本增加权重，使得新的模型重点关注误分类样本</p>
</li>
</ul>
<h3 id="AdaBoost">AdaBoost<a class="anchor-link" href="#AdaBoost">&#182;</a></h3><p>AdaBoost是AdaptiveBoost的缩写，表明该算法是具有适应性的提升算法。</p>
<p>算法的步骤如下：</p>
<p>1）给每个训练样本（$x_{1},x_{2},….,x_{N}$）分配权重，初始权重$w_{1}$均为1/N。</p>
<p>2）针对带有权值的样本进行训练，得到模型$G_m$（初始模型为G1）。</p>
<p>3）计算模型$G_m$的误分率$e_m=\sum_{i=1}^Nw_iI(y_i\not= G_m(x_i))$</p>
<p>4）计算模型$G_m$的系数$\alpha_m=0.5\log[(1-e_m)/e_m]$</p>
<p>5）根据误分率e和当前权重向量$w_m$更新权重向量$w_{m+1}$。</p>
<p>6）计算组合模型$f(x)=\sum_{m=1}^M\alpha_mG_m(x_i)$的误分率。</p>
<p>7）当组合模型的误分率或迭代次数低于一定阈值，停止迭代；否则，回到步骤2）</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
        <footer>
            <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-08-ti-sheng-fang-fa.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-09-suan-fa-ji-qi-tui-yan.html">统计学习方法09-算法及其推广</a>
        </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

    <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第9章-EM算法及其推广">&#31532;9&#31456; EM&#31639;&#27861;&#21450;&#20854;&#25512;&#24191;<a class="anchor-link" href="#第9章-EM算法及其推广">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Expectation-Maximization-algorithm">Expectation Maximization algorithm<a class="anchor-link" href="#Expectation-Maximization-algorithm">&#182;</a></h1><h3 id="Maximum-likehood-function">Maximum likehood function<a class="anchor-link" href="#Maximum-likehood-function">&#182;</a></h3><p><a href="http://fangs.in/post/thinkstats/likelihood/">likehood &amp; maximum likehood</a></p>
<blockquote><p>在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；而似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们运用出现的结果来判断这个事情本身的性质（参数），也就是似然。</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$$P(Y|\theta) = \prod[\pi p^{y_i}(1-p)^{1-y_i}+(1-\pi) q^{y_i}(1-q)^{1-y_i}]$$</p>
<h3 id="E-step:">E step:<a class="anchor-link" href="#E-step:">&#182;</a></h3><p>$$\mu^{i+1}=\frac{\pi (p^i)^{y_i}(1-(p^i))^{1-y_i}}{\pi (p^i)^{y_i}(1-(p^i))^{1-y_i}+(1-\pi) (q^i)^{y_i}(1-(q^i))^{1-y_i}}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
        <footer>
            <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-09-suan-fa-ji-qi-tui-yan.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-10-yin-ma-er-ke-fu-mo-xing.html">统计学习方法10-隐马尔科夫模型</a>
        </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

    <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第10章-隐马尔可夫模型">&#31532;10&#31456; &#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;<a class="anchor-link" href="#第10章-隐马尔可夫模型">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
        <footer>
            <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-10-yin-ma-er-ke-fu-mo-xing.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-11-tiao-jian-sui-ji-chang.html">统计学习方法11-条件随机场</a>
        </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

    <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第11章-条件随机场">&#31532;11&#31456; &#26465;&#20214;&#38543;&#26426;&#22330;<a class="anchor-link" href="#第11章-条件随机场">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="例11.1">&#20363;11.1<a class="anchor-link" href="#例11.1">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
        <footer>
            <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-11-tiao-jian-sui-ji-chang.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/10k-meansju-lei.html">10.k-means聚类</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第 10 章 K-Means（K-均值）聚类算法</h1>
<h2>K-Means 算法</h2>
<p>聚类是一种无监督的学习, 它将相似的对象归到一个簇中, 将不相似对象归到不同簇中.<br/>
相似这一概念取决于所选择的相似度计算方法.<br/>
K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 <code>K-均值</code> 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.<br/>
簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.<br/>
聚类与分类算法的最大区别在于, 分类的目标类别已知 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/10k-meansju-lei.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">11.Apriori-关联分析</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第 11 章 使用 Apriori 算法进行关联分析</h1>
<h2>关联分析</h2>
<p>关联分析是一种在大规模数据集中寻找有趣关系的任务。
这些关系可以有两种形式: 
<em> 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。
</em> 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。</p>
<h2>相关术语</h2>
<ul>
<li>
<p>关联分析（关联规则学习): 从大规模数据集中寻找物品间的隐含关系被称作 <code>关联分析(associati analysis)</code> 或者 <code>关联规则学习（association rule learning …</code></p></li></ul></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">12.FP-growth-频繁项集</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第12章 使用FP-growth算法来高效发现频繁项集</h1>
<h2>前言</h2>
<p>在 <a href="">第11章</a> 时我们已经介绍了用 <code>Apriori</code> 算法发现 <code>频繁项集</code> 与 <code>关联规则</code>。<br/>
本章将继续关注发现 <code>频繁项集</code> 这一任务，并使用 <code>FP-growth</code> 算法更有效的挖掘 <code>频繁项集</code>。</p>
<h2>FP-growth 算法简介</h2>
<ul>
<li>一种非常好的发现频繁项集算法。</li>
<li>基于Apriori算法构建,但是数据结构不同，使用叫做 <code>FP树</code> 的数据结构结构来存储集合。下面我们会介绍这种数据结构。</li>
</ul>
<h2>FP-growth 算法步骤</h2>
<ul>
<li>基于数据构建FP树 …</li></ul></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">13.利用PCA来简化数据</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第13章 利用 PCA 来简化数据</h1>
<h2>降维技术</h2>
<blockquote>
<p>场景</p>
</blockquote>
<ul>
<li>我们正通过电视观看体育比赛，在电视的显示器上有一个球。</li>
<li>显示器大概包含了100万像素点，而球则可能是由较少的像素点组成，例如说一千个像素点。</li>
<li>人们实时的将显示器上的百万像素转换成为一个三维图像，该图像就给出运动场上球的位置。</li>
<li>在这个过程中，人们已经将百万像素点的数据，降至为三维。这个过程就称为<code>降维(dimensionality reduction)</code></li>
</ul>
<blockquote>
<p>数据显示 并非大规模特征下的唯一难题，对数据进行简化还有如下一系列的原因：</p>
</blockquote>
<ul>
<li>1) 使得数据集更容易使用</li>
<li>2) 降低很多算法的计算开销</li>
<li>3) 去除噪音</li>
<li>4 …</li></ul></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">14.利用SVD简化数据</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第14章 利用SVD简化数据</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>SVD 概述</h2>
<div class="highlight"><pre><span></span>奇异值分解（SVD, Singular Value Decomposition）:
    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。
</pre></div>
<h2>SVD 场景</h2>
<blockquote>
<p>信息检索-隐性语义检索（Lstent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p>
</blockquote>
<p>隐性语义索引 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">15.大数据与MapReduce</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第15章 大数据与MapReduce</h1>
<h2>大数据 概述</h2>
<p><code>大数据: 收集到的数据已经远远超出了我们的处理能力。</code></p>
<h2>大数据 场景</h2>
<div class="highlight"><pre><span></span>假如你为一家网络购物商店工作，很多用户访问该网站，其中有些人会购买商品，有些人则随意浏览后就离开。
对于你来说，可能很想识别那些有购物意愿的用户。
那么问题就来了，数据集可能会非常大，在单机上训练要运行好几天。
接下来：我们讲讲 MapRedece 如何来解决这样的问题
</pre></div>
<h2>MapRedece</h2>
<h3>Hadoop 概述</h3>
<div class="highlight"><pre><span></span>Hadoop 是 MapRedece 框架的一个免费开源实现。
MapReduce: 分布式的计算框架 …</pre></div></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/16tui-jian-xi-tong.html">16.推荐系统</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第16章 推荐系统</h1>
<h2>背景与挖掘目标</h2>
<p>随着互联网的快速发展，用户很难快速从海量信息中寻找到自己感兴趣的信息。因此诞生了：搜索引擎+推荐系统</p>
<p>本章节-推荐系统：</p>
<ol>
<li>帮助用户发现其感兴趣和可能感兴趣的信息。</li>
<li>让网站价值信息脱颖而出，得到广大用户的认可。</li>
<li>提高用户对网站的忠诚度和关注度，建立稳固用户群体。</li>
</ol>
<h2>分析方法与过程</h2>
<p>本案例的目标是对用户进行推荐，即以一定的方式将用户与物品（本次指网页）之间建立联系。</p>
<p>由于用户访问网站的数据记录很多，如果不对数据进行分类处理，对所有的记录直接采用推荐系统进行推荐，这样会存在一下问题。</p>
<ol>
<li>数据量太大意味着物品数与用户数很多，在模型构建用户与物品稀疏矩阵时，出现设备内存空间不够的情况，并且模型计算需要消耗大量的时间。</li>
<li>用户区别很大，不同的用户关注的信息不一样，因此 …</li></ol></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/16tui-jian-xi-tong.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">1.机器学习基础</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第1章 机器学习基础</h1>
<h2>机器学习 概述</h2>
<p><code>机器学习(Machine Learning,ML)</code> 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。</p>
<ol>
<li>海量的数据</li>
<li>获取有用的信息</li>
</ol>
<h2>机器学习 研究意义</h2>
<p>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/2k-jin-lin-suan-fa.html">2.k-近邻算法</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第2章 k-近邻算法</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>KNN 概述</h2>
<p><code>k-近邻（kNN, k-NearestNeighbor）算法是一种基本分类与回归方法，我们这里只讨论分类问题中的 k-近邻算法。</code></p>
<p><strong>一句话总结：近朱者赤近墨者黑！</strong> </p>
<p><code>k 近邻算法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k 近邻算法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻算法不具有显式的学习过程。</code></p>
<p><code>k 近邻算法实际上利用训练数据集对特征向量空间进行划分 …</code></p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/2k-jin-lin-suan-fa.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/3jue-ce-shu.html">3.决策树</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第3章 决策树</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>决策树 概述</h2>
<p><code>决策树（Decision Tree）算法是一种基本的分类与回归方法，是最经常使用的数据挖掘算法之一。我们这章节只讨论用于分类的决策树。</code></p>
<p><code>决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。</code></p>
<p><code>决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪。</code></p>
<h2>决策树 场景</h2>
<p>一个叫做 "二十个问题" 的游戏，游戏的规则很简单：参与游戏的一方在脑海中想某个事物，其他参与者向他提问 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/3jue-ce-shu.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/4po-su-bei-xie-si.html">4.朴素贝叶斯</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第4章 基于概率论的分类方法：朴素贝叶斯</h1>
<h2>朴素贝叶斯 概述</h2>
<p><code>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。本章首先介绍贝叶斯分类算法的基础——贝叶斯定理。最后，我们通过实例来讨论贝叶斯分类的中最简单的一种: 朴素贝叶斯分类。</code></p>
<h2>贝叶斯理论 &amp; 条件概率</h2>
<h3>贝叶斯理论</h3>
<p>我们现在有一个数据集，它由两类数据组成，数据分布如下图所示：</p>
<p><img alt="朴素贝叶斯示例数据分布" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/朴素贝叶斯示例数据分布.png" title="参数已知的概率分布"/></p>
<p>我们现在用 p1(x,y) 表示数据点 (x,y) 属于类别 1（图中用圆点表示的类别）的概率 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/4po-su-bei-xie-si.html">Read On &crarr;</a>
        </footer>


                </article>
<div class="pagination">
    <a class="prev" href="./index13.html">&larr; Older</a>

    <a class="next" href="./index11.html">Newer &rarr;</a>
  <br />
</div>    </div>
<aside class="sidebar">
    <section>
        <h1>Recent Posts</h1>
        <ul id="recent_posts">
                <li class="post">
                    <a href="./pages/2019/01/21-a-first-look-at-a-neural-network.html">2.1-a-first-look-at-a-neural-network</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/35-classifying-movie-reviews.html">3.5-classifying-movie-reviews</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/36-classifying-newswires.html">3.6-classifying-newswires</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/37-predicting-house-prices.html">3.7-predicting-house-prices</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/44-overfitting-and-underfitting.html">4.4-overfitting-and-underfitting</a>
                </li>
        </ul>
    </section>
        <section>

            <h1>Categories</h1>
            <ul id="recent_posts">
                    <li><a href="./category/01chang yong gong ju.html">01常用工具</a></li>
                    <li><a href="./category/02.wo ai du shu.html">02.我爱读书</a></li>
                    <li><a href="./category/algorithms.html">algorithms</a></li>
                    <li><a href="./category/book.html">book</a></li>
                    <li><a href="./category/book-pydata.html">book-pydata</a></li>
                    <li><a href="./category/deep-learning-with-python.html">deep-learning-with-python</a></li>
                    <li><a href="./category/ji qi xue xi shi zhan.html">机器学习实战</a></li>
                    <li><a href="./category/ke wai du wu.html">课外读物</a></li>
                    <li><a href="./category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a></li>
                    <li><a href="./category/shen du xue xi.html">深度学习</a></li>
                    <li><a href="./category/shen jing wang luo.html">神经网络</a></li>
                    <li><a href="./category/shu ju wa jue.html">数据挖掘</a></li>
                    <li><a href="./category/shu xue ji chu.html">数学基础</a></li>
                    <li><a href="./category/tf-example.html">tf-example</a></li>
                    <li><a href="./category/tool1.html">tool1</a></li>
                    <li><a href="./category/tool2.html">tool2</a></li>
                    <li><a href="./category/tools.html">tools</a></li>
                    <li><a href="./category/tui jian xi tong.html">推荐系统</a></li>
                    <li><a href="./category/wen ben wa jue.html">文本挖掘</a></li>
            </ul>
        </section>


    <section>
        <h1>Tags</h1>
            <a href="./tag/python.html">python</a>, 
            <a href="./tag/numpy.html">numpy</a>, 
            <a href="./tag/deep-learning.html">deep-learning</a>, 
            <a href="./tag/algorithms.html">algorithms</a>, 
            <a href="./tag/wen-ben-wa-jue.html">文本挖掘</a>, 
            <a href="./tag/shen-jing-wang-luo.html">神经网络</a>, 
            <a href="./tag/shu-xue-ji-chu.html">数学基础</a>, 
            <a href="./tag/nlp.html">nlp</a>, 
            <a href="./tag/tf-example.html">tf-example</a>, 
            <a href="./tag/tui-jian-xi-tong.html">推荐系统</a>, 
            <a href="./tag/tf.html">tf</a>, 
            <a href="./tag/ji-huo-han-shu.html">激活函数</a>, 
            <a href="./tag/mapreduce.html">mapreduce</a>, 
            <a href="./tag/spark.html">spark</a>, 
            <a href="./tag/handbook.html">handbook</a>, 
            <a href="./tag/matplotlib.html">matplotlib</a>, 
            <a href="./tag/scikit-learn.html">scikit-learn</a>, 
            <a href="./tag/latex.html">latex</a>, 
            <a href="./tag/pandas.html">pandas</a>, 
            <a href="./tag/jupyter.html">jupyter</a>, 
            <a href="./tag/plot.html">plot</a>, 
            <a href="./tag/pip.html">pip</a>, 
            <a href="./tag/geng-xin-suo-you-mo-kuai.html">更新所有模块</a>, 
            <a href="./tag/shen-du-xue-xi.html">深度学习</a>, 
            <a href="./tag/xun-huan-shen-jing-wang-luo.html">循环神经网络</a>, 
            <a href="./tag/pangrank.html">PangRank</a>, 
            <a href="./tag/book.html">book</a>, 
            <a href="./tag/pydata.html">pydata</a>, 
            <a href="./tag/shell.html">shell</a>, 
            <a href="./tag/pyhton.html">pyhton</a>
    </section>



    <section>
        <h1>GitHub Repos</h1>
            <a href="https://github.com/1007530194">@1007530194</a> on GitHub
    </section>

</aside>    </div>
</div>
<footer role="contentinfo"><p>
        活到老，学到老，玩到老
    <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>

    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-132396898-1', 'auto');

    ga('require', 'displayfeatures');
    ga('send', 'pageview');
    </script>
</body>
</html>